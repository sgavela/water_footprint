{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b797ed56",
   "metadata": {},
   "source": [
    "En este notebook se recogen varias pruebas solo con los contadores cuyas series temporales son completas o casi completas.\n",
    "\n",
    "**PRUEBAS HECHAS**\n",
    "1. Predicción haciendo la media entre XGBoost Regressor y Gradient Boosting Regressor (BASELINE ENTREGA LOCAL)\n",
    "2. El 1 pero hacemos un modelo agregado por semanas para las predicciones agregadas semanales (EMPEORA)\n",
    "3. Meter variable lag_7 y lag_14 (MEJORA)\n",
    "4. Hacer selección de variables atendiendo a las features_importances_ de XGBoost (MEJORA sospechosamente MUCHO)\n",
    "\n",
    "**PRUEBAS POR HACER**\n",
    "- Usar de train menos meses\n",
    "- Quitar predicciones negativas (ponerlas a 0 y a funcionar)\n",
    "- Usar catboost en vez de xgboost\n",
    "- Probar a hacer un modelo agregado semanal pero usando ARIMA\n",
    "- Probar modelo diario con ARIMA (solo en contadores buenos)\n",
    "- Quitar outlayers (esto es más en preprocesado)\n",
    "- Hacer logaritmos a (casi) todo\n",
    "- LSTM (a saber qué se puede gestionar con esto) (puede ser buena idea no usar toda la serie temporal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd1a1e2",
   "metadata": {},
   "source": [
    "### Imports, utils and train/test creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4264b860",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9180493c",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c532c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "given a start date in datetime format \"start_date\" and an \"end_date\" returns a list of strings with the dates from\n",
    "\"start_date\" to \"end_date\".\n",
    "\n",
    "Example:\n",
    "\n",
    "start_date = datetime.date(2019, 9 , 30)\n",
    "end_date = datetime.date(2019, 10, 7)\n",
    "get_date_range(start_date, end_date)\n",
    "'''\n",
    "def get_date_range(start_date, end_date):\n",
    "    number_of_days = (end_date-start_date).days\n",
    "    return [(start_date + datetime.timedelta(days = day)).isoformat() for day in range(number_of_days+1)]\n",
    "\n",
    "'''\n",
    "This function expects two dataframes with the same format: for the first seven columns, each column corresponds to a date \n",
    "and each row corresponds to a counter index. In position i,j there should be DELTA of counter i in date j. \n",
    "For the last two columns of the dataframes they should not reffer to a daily prediction but to the aggregated prediction \n",
    "of week_1 and week_2. Given these two dataframes (one for theprediction and one for the real values), \n",
    "the function returns de error according to the competition rules.\n",
    "\n",
    "Examples:\n",
    "\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "test = pd.read_pickle('../data/test.pkl')\n",
    "\n",
    "compute_error(test, test)\n",
    "\n",
    "test_v3 = copy.copy(test)\n",
    "test_v3.iloc[:,0] = test_v3.iloc[:,1]\n",
    "compute_error(test_v3, test)\n",
    "\n",
    "'''\n",
    "def compute_error(pred, real):\n",
    "    daily_rmses = []\n",
    "    for i in range(7):\n",
    "        daily_rmses.append((((real.iloc[:,i] - pred.iloc[:,i])**2/len(real.iloc[:,i])).sum())**(1/2))\n",
    "    rmse_1 = sum(daily_rmses)/7\n",
    "    \n",
    "    first_week_pred_sum = pred.iloc[:,7].sum()\n",
    "    second_week_pred_sum = pred.iloc[:,8].sum()\n",
    "    first_week_real_sum = real.iloc[:,7].sum()\n",
    "    second_week_real_sum = real.iloc[:,8].sum()\n",
    "    \n",
    "    first_week_rmse = (((first_week_real_sum - first_week_pred_sum)**2)/len(real.iloc[:,7]))**(1/2)\n",
    "    second_week_rmse = (((second_week_real_sum - second_week_pred_sum)**2)/len(real.iloc[:,8]))**(1/2)\n",
    "    rmse_2 = (first_week_rmse + second_week_rmse)/2\n",
    "    \n",
    "    return (rmse_1 + rmse_2)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57e11418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (931203, 14) Test: (37142, 15)\n"
     ]
    }
   ],
   "source": [
    "path = '../data/df6.pkl'\n",
    "\n",
    "df = pd.read_pickle(path)\n",
    "start_date = datetime.date(2019, 2 , 1)\n",
    "end_date = datetime.date(2020, 1, 17)\n",
    "train = df[df['DATE'].isin(get_date_range(start_date, end_date))]\n",
    "train = train[train['IS_GOOD']==1]\n",
    "train.drop(['YEAR_DAY','WEEKDAY','IS_GOOD','DATE'], axis=1, inplace=True)\n",
    "train['SUN'] = train['SUN'].fillna(train['SUN'].mean())\n",
    "train['PRECIPITATIONS'] = train['PRECIPITATIONS'].fillna(train['PRECIPITATIONS'].mean())\n",
    "\n",
    "start_date = datetime.date(2020, 1 , 18)\n",
    "end_date = datetime.date(2020, 1, 31)\n",
    "test = df[df['DATE'].isin(get_date_range(start_date, end_date))]\n",
    "test = test[test['IS_GOOD']==1]\n",
    "test.drop(['YEAR_DAY','WEEKDAY','IS_GOOD'], axis=1, inplace=True)\n",
    "test['SUN'] = test['SUN'].fillna(test['SUN'].mean())\n",
    "test['PRECIPITATIONS'] = test['PRECIPITATIONS'].fillna(test['PRECIPITATIONS'].mean())\n",
    "\n",
    "print('Train:', train.shape, 'Test:', test.shape)\n",
    "\n",
    "X_train = train.drop(['DELTA'], axis=1)\n",
    "y_train = train['DELTA']\n",
    "\n",
    "X_test = test.drop(['DELTA', 'DATE'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc07ccf",
   "metadata": {},
   "source": [
    "### XGBR and GBR for all counters\n",
    "\n",
    "- The final prediction is the mean between XGBR and GBR\n",
    "- No lags are used\n",
    "- The week prediction is done just by adding the daily predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a1c5f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (964197, 14) Test: (38458, 15)\n"
     ]
    }
   ],
   "source": [
    "path = '../data/df6.pkl'\n",
    "\n",
    "df = pd.read_pickle(path)\n",
    "start_date = datetime.date(2019, 2 , 1)\n",
    "end_date = datetime.date(2020, 1, 17)\n",
    "train = df[df['DATE'].isin(get_date_range(start_date, end_date))]\n",
    "train.drop(['YEAR_DAY','WEEKDAY','IS_GOOD','DATE'], axis=1, inplace=True)\n",
    "train['SUN'] = train['SUN'].fillna(train['SUN'].mean())\n",
    "train['PRECIPITATIONS'] = train['PRECIPITATIONS'].fillna(train['PRECIPITATIONS'].mean())\n",
    "\n",
    "start_date = datetime.date(2020, 1 , 18)\n",
    "end_date = datetime.date(2020, 1, 31)\n",
    "test = df[df['DATE'].isin(get_date_range(start_date, end_date))]\n",
    "test.drop(['YEAR_DAY','WEEKDAY','IS_GOOD'], axis=1, inplace=True)\n",
    "test['SUN'] = test['SUN'].fillna(test['SUN'].mean())\n",
    "test['PRECIPITATIONS'] = test['PRECIPITATIONS'].fillna(test['PRECIPITATIONS'].mean())\n",
    "\n",
    "print('Train:', train.shape, 'Test:', test.shape)\n",
    "\n",
    "X_train = train.drop(['DELTA'], axis=1)\n",
    "y_train = train['DELTA']\n",
    "\n",
    "X_test = test.drop(['DELTA', 'DATE'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b96c32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting XGB...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m model2 \u001b[38;5;241m=\u001b[39m GradientBoostingRegressor()\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFitting XGB...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m \u001b[43mmodel1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFitting GB...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m model2\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\xgboost\\core.py:506\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    505\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 506\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\xgboost\\sklearn.py:789\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m    786\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    788\u001b[0m model, feval, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, eval_metric, params)\n\u001b[1;32m--> 789\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\xgboost\\training.py:188\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(params, dtrain, num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, evals\u001b[38;5;241m=\u001b[39m(), obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, feval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    116\u001b[0m           maximize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, evals_result\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    117\u001b[0m           verbose_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, xgb_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# pylint: disable=too-many-statements,too-many-branches, attribute-defined-outside-init\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;124;03m\"\"\"Train a booster with given parameters.\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \n\u001b[0;32m    121\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;124;03m    Booster : a trained booster model\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 188\u001b[0m     bst \u001b[38;5;241m=\u001b[39m \u001b[43m_train_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxgb_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bst\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\xgboost\\training.py:81\u001b[0m, in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callbacks\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 81\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callbacks\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\xgboost\\core.py:1680\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_features(dtrain)\n\u001b[0;32m   1679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1680\u001b[0m     _check_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1681\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1682\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1683\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1684\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model1 = xgb.XGBRegressor(\n",
    "    n_estimators=1000,\n",
    "    reg_lambda=1,\n",
    "    gamma=0,\n",
    "    max_depth=8\n",
    ")\n",
    "\n",
    "model2 = GradientBoostingRegressor()\n",
    "\n",
    "print('Fitting XGB...')\n",
    "model1.fit(X_train, y_train)\n",
    "print('Fitting GB...')\n",
    "model2.fit(X_train, y_train)\n",
    "print('End fitting.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d61746",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = model1.predict(X_test)\n",
    "y_pred2 = model2.predict(X_test)\n",
    "\n",
    "results_df = pd.DataFrame.from_dict({'ID':test['ID'].values, \n",
    "                                     'DATE':test['DATE'].values,\n",
    "                                     'y_pred1':y_pred1,\n",
    "                                     'y_pred2':y_pred2})\n",
    "results_df = results_df.sort_values(['ID','DATE'])\n",
    "results_df['FINAL'] = results_df[['y_pred1','y_pred2']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b844de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.date(2020, 1 , 18)\n",
    "end_date = datetime.date(2020, 1, 31)\n",
    "fechas_test = get_date_range(start_date, end_date)\n",
    "\n",
    "ID = []\n",
    "Dia_1 = []\n",
    "Dia_2 = []\n",
    "Dia_3 = []\n",
    "Dia_4 = []\n",
    "Dia_5 = []\n",
    "Dia_6 = []\n",
    "Dia_7 = []\n",
    "for i, fecha in enumerate(fechas_test[0:7]):\n",
    "    aux = results_df[results_df['DATE']==fecha]\n",
    "    ID = list(aux['ID'].values)\n",
    "    if i==0:\n",
    "        Dia_1 += list(aux['FINAL'].values)\n",
    "    if i==1:\n",
    "        Dia_2 += list(aux['FINAL'].values)\n",
    "    if i==2:\n",
    "        Dia_3 += list(aux['FINAL'].values)\n",
    "    if i==3:\n",
    "        Dia_4 += list(aux['FINAL'].values)\n",
    "    if i==4:\n",
    "        Dia_5 += list(aux['FINAL'].values)\n",
    "    if i==5:\n",
    "        Dia_6 += list(aux['FINAL'].values)\n",
    "    if i==6:\n",
    "        Dia_7 += list(aux['FINAL'].values)\n",
    "print(len(ID),len(Dia_1))\n",
    "final_df = pd.DataFrame.from_dict({'ID':ID,\n",
    "                                   'Dia_1':Dia_1,\n",
    "                                  'Dia_2':Dia_2,\n",
    "                                  'Dia_3':Dia_3,\n",
    "                                  'Dia_4':Dia_4,\n",
    "                                  'Dia_5':Dia_5,\n",
    "                                  'Dia_6':Dia_6,\n",
    "                                  'Dia_7':Dia_7,})\n",
    "\n",
    "ID = []\n",
    "Dia_8 = []\n",
    "Dia_9 = []\n",
    "Dia_10 = []\n",
    "Dia_11 = []\n",
    "Dia_12 = []\n",
    "Dia_13 = []\n",
    "Dia_14 = []\n",
    "for i, fecha in enumerate(fechas_test[7:14]):\n",
    "    aux = results_df[results_df['DATE']==fecha]\n",
    "    ID = list(aux['ID'].values)\n",
    "    if i==0:\n",
    "        Dia_8 += list(aux['FINAL'].values)\n",
    "    if i==1:\n",
    "        Dia_9 += list(aux['FINAL'].values)\n",
    "    if i==2:\n",
    "        Dia_10 += list(aux['FINAL'].values)\n",
    "    if i==3:\n",
    "        Dia_11 += list(aux['FINAL'].values)\n",
    "    if i==4:\n",
    "        Dia_12 += list(aux['FINAL'].values)\n",
    "    if i==5:\n",
    "        Dia_13 += list(aux['FINAL'].values)\n",
    "    if i==6:\n",
    "        Dia_14 += list(aux['FINAL'].values)\n",
    "print(len(ID),len(Dia_11))\n",
    "final_df2 = pd.DataFrame.from_dict({'ID':ID,\n",
    "                                   'Dia_8':Dia_8,\n",
    "                                  'Dia_9':Dia_9,\n",
    "                                  'Dia_10':Dia_10,\n",
    "                                  'Dia_11':Dia_11,\n",
    "                                  'Dia_12':Dia_12,\n",
    "                                  'Dia_13':Dia_13,\n",
    "                                  'Dia_14':Dia_14,})\n",
    "\n",
    "final_df['Semana_1'] = final_df[['Dia_1','Dia_2','Dia_3','Dia_4','Dia_5','Dia_6','Dia_7']].sum(axis=1)\n",
    "final_df['Semana_2'] = final_df2[['Dia_8','Dia_9','Dia_10','Dia_11','Dia_12','Dia_13','Dia_14']].sum(axis=1)\n",
    "\n",
    "final_df2 = final_df.drop('ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1784342",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_pickle('../data/test.pkl')\n",
    "error = compute_error(final_df2, test)\n",
    "print('Mean between XGBR and GBR:', round(error,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac4bdcf",
   "metadata": {},
   "source": [
    "### Train and test sets for weekly predictions instead of adding daily predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78814ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/df6.pkl'\n",
    "\n",
    "df = pd.read_pickle(path)\n",
    "start_date = datetime.date(2019, 2 , 1)\n",
    "end_date = datetime.date(2020, 1, 17)\n",
    "week_train = df[df['DATE'].isin(get_date_range(start_date, end_date))]\n",
    "week_train['YEAR_WEEK'] = (week_train['YEAR_DAY']-1)//7\n",
    "week_train = week_train[week_train['YEAR_WEEK']!=-1]\n",
    "week_train.drop(['YEAR_DAY','IS_WEEKEND','WEEKDAY','sin_WEEKDAY','cos_WEEKDAY',\n",
    "                 'sin_year_day','cos_year_day','IS_GOOD','DATE'], axis=1, inplace = True)\n",
    "\n",
    "week_train = week_train.groupby(['YEAR_WEEK','ID']).agg({ \n",
    "                                     'DELTA':sum,\n",
    "                                     'PRECIPITATIONS':np.mean,\n",
    "                                     'MIN_TEMP':min,\n",
    "                                     'MEAN_TEMP':np.mean,\n",
    "                                     'MAX_TEMP':max,\n",
    "                                     'SUN':np.mean,\n",
    "                                     'MEAN_CONSUMPTION':np.mean,\n",
    "                                     'VARIANCE_CONSUMPTION':np.mean}).reset_index()\n",
    "\n",
    "weeks_in_a_year = 50\n",
    "week_train['sin_YEAR_WEEK'] = np.sin(2*np.pi*week_train['YEAR_WEEK']/weeks_in_a_year)\n",
    "week_train['cos_YEAR_WEEK'] = np.cos(2*np.pi*week_train['YEAR_WEEK']/weeks_in_a_year) \n",
    "week_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984219a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = week_train.drop(['DELTA','YEAR_WEEK'], axis=1)\n",
    "y_train = week_train['DELTA']\n",
    "\n",
    "model1 = xgb.XGBRegressor(\n",
    "    n_estimators=1000,\n",
    "    reg_lambda=1,\n",
    "    gamma=0,\n",
    "    max_depth=8\n",
    ")\n",
    "model2 = GradientBoostingRegressor()\n",
    "\n",
    "print('Fitting XGB...')\n",
    "model1.fit(X_train, y_train)\n",
    "print('Fitting GB...')\n",
    "model2.fit(X_train, y_train)\n",
    "print('End fitting.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515bc04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/df6.pkl'\n",
    "\n",
    "df = pd.read_pickle(path)\n",
    "start_date = datetime.date(2020, 1 , 18)\n",
    "end_date = datetime.date(2020, 1, 31)\n",
    "week_test = df[df['DATE'].isin(get_date_range(start_date, end_date))]\n",
    "week_test['YEAR_WEEK'] = (week_test['YEAR_DAY']-1)//7\n",
    "week_test = week_test[week_test['YEAR_WEEK']!=-1]\n",
    "week_test.drop(['YEAR_DAY','IS_WEEKEND','WEEKDAY','sin_WEEKDAY','cos_WEEKDAY',\n",
    "                 'sin_year_day','cos_year_day','IS_GOOD','DATE'], axis=1, inplace = True)\n",
    "\n",
    "week_test = week_test.groupby(['YEAR_WEEK','ID']).agg({ \n",
    "                                     'DELTA':sum,\n",
    "                                     'PRECIPITATIONS':np.mean,\n",
    "                                     'MIN_TEMP':min,\n",
    "                                     'MEAN_TEMP':np.mean,\n",
    "                                     'MAX_TEMP':max,\n",
    "                                     'SUN':np.mean,\n",
    "                                     'MEAN_CONSUMPTION':np.mean,\n",
    "                                     'VARIANCE_CONSUMPTION':np.mean}).reset_index()\n",
    "\n",
    "weeks_in_a_year = 50\n",
    "week_test['sin_YEAR_WEEK'] = np.sin(2*np.pi*week_test['YEAR_WEEK']/weeks_in_a_year)\n",
    "week_test['cos_YEAR_WEEK'] = np.cos(2*np.pi*week_test['YEAR_WEEK']/weeks_in_a_year) \n",
    "\n",
    "X_test = week_test.drop(['DELTA','YEAR_WEEK'], axis=1)\n",
    "y_test = week_test['DELTA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa44cca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = model1.predict(X_test)\n",
    "y_pred2 = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c108c902",
   "metadata": {},
   "outputs": [],
   "source": [
    "week_test['prediction1'] = y_pred1\n",
    "week_test['prediction2'] = y_pred2\n",
    "week_test['prediction'] = (week_test['prediction1'] + week_test['prediction2'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68713fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df2['Semana_1'] = week_test[week_test['YEAR_WEEK']==50]['prediction']\n",
    "final_df2['Semana_2'] = week_test[week_test['YEAR_WEEK']==51]['prediction']\n",
    "\n",
    "test = pd.read_pickle('../data/test.pkl')\n",
    "error = compute_error(final_df2, test)\n",
    "print('Mean between XGBR and GBR:', round(error,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35f3c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "week_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6252af89",
   "metadata": {},
   "source": [
    "### Incluyendo lag_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9aca08",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/df6.pkl'\n",
    "\n",
    "df = pd.read_pickle(path)\n",
    "df['LAG_7'] = df['DELTA'].shift(7, fill_value=0)\n",
    "df['LAG_14'] = df['DELTA'].shift(14, fill_value=0)\n",
    "\n",
    "start_date = datetime.date(2019, 2 , 1)\n",
    "end_date = datetime.date(2020, 1, 17)\n",
    "train = df[df['DATE'].isin(get_date_range(start_date, end_date))]\n",
    "train = train[train['IS_GOOD']==1]\n",
    "train.drop(['YEAR_DAY','WEEKDAY','IS_GOOD','DATE'], axis=1, inplace=True)\n",
    "train['SUN'] = train['SUN'].fillna(train['SUN'].mean())\n",
    "train['PRECIPITATIONS'] = train['PRECIPITATIONS'].fillna(train['PRECIPITATIONS'].mean())\n",
    "\n",
    "start_date = datetime.date(2020, 1 , 18)\n",
    "end_date = datetime.date(2020, 1, 24)\n",
    "test = df[df['DATE'].isin(get_date_range(start_date, end_date))]\n",
    "test = test[test['IS_GOOD']==1]\n",
    "test.drop(['YEAR_DAY','WEEKDAY','IS_GOOD'], axis=1, inplace=True)\n",
    "test['SUN'] = test['SUN'].fillna(test['SUN'].mean())\n",
    "test['PRECIPITATIONS'] = test['PRECIPITATIONS'].fillna(test['PRECIPITATIONS'].mean())\n",
    "\n",
    "start_date = datetime.date(2020, 1 , 25)\n",
    "end_date = datetime.date(2020, 1, 31)\n",
    "test_2 = df[df['DATE'].isin(get_date_range(start_date, end_date))]\n",
    "test_2 = test_2[test_2['IS_GOOD']==1]\n",
    "test_2.drop(['YEAR_DAY','WEEKDAY','IS_GOOD'], axis=1, inplace=True)\n",
    "test_2['SUN'] = test_2['SUN'].fillna(test_2['SUN'].mean())\n",
    "test_2['PRECIPITATIONS'] = test_2['PRECIPITATIONS'].fillna(test['PRECIPITATIONS'].mean())\n",
    "\n",
    "print('Train:', train.shape, 'Test:', test.shape, 'Test 2:', test_2.shape)\n",
    "\n",
    "X_train = train.drop(['DELTA'], axis=1)\n",
    "y_train = train['DELTA']\n",
    "\n",
    "X_test = test.drop(['DELTA', 'DATE'], axis=1)\n",
    "X_test_2 = test_2.drop(['DELTA', 'DATE'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c9ca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = xgb.XGBRegressor(\n",
    "    n_estimators=1000,\n",
    "    reg_lambda=1,\n",
    "    gamma=0,\n",
    "    max_depth=8\n",
    ")\n",
    "\n",
    "model2 = GradientBoostingRegressor()\n",
    "\n",
    "print('Fitting XGB...')\n",
    "model1.fit(X_train, y_train)\n",
    "print('Fitting GB...')\n",
    "model2.fit(X_train, y_train)\n",
    "print('End fitting.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20807f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = model1.predict(X_test)\n",
    "y_pred2 = model2.predict(X_test)\n",
    "\n",
    "results_df = pd.DataFrame.from_dict({'ID':test['ID'].values, \n",
    "                                     'DATE':test['DATE'].values,\n",
    "                                     'y_pred1':y_pred1,\n",
    "                                     'y_pred2':y_pred2})\n",
    "results_df = results_df.sort_values(['ID','DATE'])\n",
    "results_df['FINAL'] = results_df[['y_pred1','y_pred2']].mean(axis=1)\n",
    "\n",
    "X_test_2['LAG_7'] = results_df['FINAL'].values\n",
    "\n",
    "y_pred1_2 = model1.predict(X_test_2)\n",
    "y_pred2_2 = model2.predict(X_test_2)\n",
    "\n",
    "results_df_2 = pd.DataFrame.from_dict({'ID':test_2['ID'].values, \n",
    "                                     'DATE':test_2['DATE'].values,\n",
    "                                     'y_pred1':y_pred1,\n",
    "                                     'y_pred2':y_pred2})\n",
    "results_df_2 = results_df_2.sort_values(['ID','DATE'])\n",
    "results_df_2['FINAL'] = results_df_2[['y_pred1','y_pred2']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951aec88",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.concat([results_df, results_df_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821c1b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.date(2020, 1 , 18)\n",
    "end_date = datetime.date(2020, 1, 31)\n",
    "fechas_test = get_date_range(start_date, end_date)\n",
    "\n",
    "ID = []\n",
    "Dia_1 = []\n",
    "Dia_2 = []\n",
    "Dia_3 = []\n",
    "Dia_4 = []\n",
    "Dia_5 = []\n",
    "Dia_6 = []\n",
    "Dia_7 = []\n",
    "for i, fecha in enumerate(fechas_test[0:7]):\n",
    "    aux = results_df[results_df['DATE']==fecha]\n",
    "    ID = list(aux['ID'].values)\n",
    "    if i==0:\n",
    "        Dia_1 += list(aux['FINAL'].values)\n",
    "    if i==1:\n",
    "        Dia_2 += list(aux['FINAL'].values)\n",
    "    if i==2:\n",
    "        Dia_3 += list(aux['FINAL'].values)\n",
    "    if i==3:\n",
    "        Dia_4 += list(aux['FINAL'].values)\n",
    "    if i==4:\n",
    "        Dia_5 += list(aux['FINAL'].values)\n",
    "    if i==5:\n",
    "        Dia_6 += list(aux['FINAL'].values)\n",
    "    if i==6:\n",
    "        Dia_7 += list(aux['FINAL'].values)\n",
    "print(len(ID),len(Dia_1))\n",
    "final_df = pd.DataFrame.from_dict({'ID':ID,\n",
    "                                   'Dia_1':Dia_1,\n",
    "                                  'Dia_2':Dia_2,\n",
    "                                  'Dia_3':Dia_3,\n",
    "                                  'Dia_4':Dia_4,\n",
    "                                  'Dia_5':Dia_5,\n",
    "                                  'Dia_6':Dia_6,\n",
    "                                  'Dia_7':Dia_7,})\n",
    "\n",
    "ID = []\n",
    "Dia_8 = []\n",
    "Dia_9 = []\n",
    "Dia_10 = []\n",
    "Dia_11 = []\n",
    "Dia_12 = []\n",
    "Dia_13 = []\n",
    "Dia_14 = []\n",
    "for i, fecha in enumerate(fechas_test[7:14]):\n",
    "    aux = results_df[results_df['DATE']==fecha]\n",
    "    ID = list(aux['ID'].values)\n",
    "    if i==0:\n",
    "        Dia_8 += list(aux['FINAL'].values)\n",
    "    if i==1:\n",
    "        Dia_9 += list(aux['FINAL'].values)\n",
    "    if i==2:\n",
    "        Dia_10 += list(aux['FINAL'].values)\n",
    "    if i==3:\n",
    "        Dia_11 += list(aux['FINAL'].values)\n",
    "    if i==4:\n",
    "        Dia_12 += list(aux['FINAL'].values)\n",
    "    if i==5:\n",
    "        Dia_13 += list(aux['FINAL'].values)\n",
    "    if i==6:\n",
    "        Dia_14 += list(aux['FINAL'].values)\n",
    "print(len(ID),len(Dia_11))\n",
    "final_df2 = pd.DataFrame.from_dict({'ID':ID,\n",
    "                                   'Dia_8':Dia_8,\n",
    "                                  'Dia_9':Dia_9,\n",
    "                                  'Dia_10':Dia_10,\n",
    "                                  'Dia_11':Dia_11,\n",
    "                                  'Dia_12':Dia_12,\n",
    "                                  'Dia_13':Dia_13,\n",
    "                                  'Dia_14':Dia_14,})\n",
    "\n",
    "final_df['Semana_1'] = final_df[['Dia_1','Dia_2','Dia_3','Dia_4','Dia_5','Dia_6','Dia_7']].sum(axis=1)\n",
    "final_df['Semana_2'] = final_df2[['Dia_8','Dia_9','Dia_10','Dia_11','Dia_12','Dia_13','Dia_14']].sum(axis=1)\n",
    "\n",
    "final_df2 = final_df.drop('ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa666c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_pickle('../data/test.pkl')\n",
    "error = compute_error(final_df2, test)\n",
    "print('Mean between XGBR and GBR:', round(error,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a312b9a",
   "metadata": {},
   "source": [
    "### Haciendo selección de variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95792a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in zip(X_train.columns, model1.feature_importances_):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c05a57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_vars = ['sin_WEEKDAY', 'MIN_TEMP', 'LAG_7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9682c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = '../data/df6.pkl'\n",
    "\n",
    "df = pd.read_pickle(path)\n",
    "df['LAG_7'] = df['DELTA'].shift(7, fill_value=0)\n",
    "df['LAG_14'] = df['DELTA'].shift(14, fill_value=0)\n",
    "\n",
    "start_date = datetime.date(2019, 2 , 1)\n",
    "end_date = datetime.date(2020, 1, 17)\n",
    "train = df[df['DATE'].isin(get_date_range(start_date, end_date))]\n",
    "train = train[train['IS_GOOD']==1]\n",
    "train.drop(['YEAR_DAY','WEEKDAY','IS_GOOD','DATE'], axis=1, inplace=True)\n",
    "train['SUN'] = train['SUN'].fillna(train['SUN'].mean())\n",
    "train['PRECIPITATIONS'] = train['PRECIPITATIONS'].fillna(train['PRECIPITATIONS'].mean())\n",
    "\n",
    "start_date = datetime.date(2020, 1 , 18)\n",
    "end_date = datetime.date(2020, 1, 24)\n",
    "test = df[df['DATE'].isin(get_date_range(start_date, end_date))]\n",
    "test = test[test['IS_GOOD']==1]\n",
    "test.drop(['YEAR_DAY','WEEKDAY','IS_GOOD'], axis=1, inplace=True)\n",
    "test['SUN'] = test['SUN'].fillna(test['SUN'].mean())\n",
    "test['PRECIPITATIONS'] = test['PRECIPITATIONS'].fillna(test['PRECIPITATIONS'].mean())\n",
    "\n",
    "start_date = datetime.date(2020, 1 , 25)\n",
    "end_date = datetime.date(2020, 1, 31)\n",
    "test_2 = df[df['DATE'].isin(get_date_range(start_date, end_date))]\n",
    "test_2 = test_2[test_2['IS_GOOD']==1]\n",
    "test_2.drop(['YEAR_DAY','WEEKDAY','IS_GOOD'], axis=1, inplace=True)\n",
    "test_2['SUN'] = test_2['SUN'].fillna(test_2['SUN'].mean())\n",
    "test_2['PRECIPITATIONS'] = test_2['PRECIPITATIONS'].fillna(test['PRECIPITATIONS'].mean())\n",
    "\n",
    "print('Train:', train.shape, 'Test:', test.shape, 'Test 2:', test_2.shape)\n",
    "\n",
    "X_train = train.drop(['DELTA'], axis=1)\n",
    "y_train = train['DELTA']\n",
    "\n",
    "X_test = test.drop(['DELTA', 'DATE'], axis=1)\n",
    "X_test_2 = test_2.drop(['DELTA', 'DATE'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bd9e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = xgb.XGBRegressor(\n",
    "    n_estimators=1000,\n",
    "    reg_lambda=1,\n",
    "    gamma=0,\n",
    "    max_depth=8\n",
    ")\n",
    "\n",
    "model2 = GradientBoostingRegressor()\n",
    "\n",
    "print('Fitting XGB...')\n",
    "model1.fit(X_train[best_vars], y_train)\n",
    "print('Fitting GB...')\n",
    "model2.fit(X_train[best_vars], y_train)\n",
    "print('End fitting.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66e32e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = model1.predict(X_test[best_vars])\n",
    "y_pred2 = model2.predict(X_test[best_vars])\n",
    "\n",
    "results_df = pd.DataFrame.from_dict({'ID':test['ID'].values, \n",
    "                                     'DATE':test['DATE'].values,\n",
    "                                     'y_pred1':y_pred1,\n",
    "                                     'y_pred2':y_pred2})\n",
    "results_df = results_df.sort_values(['ID','DATE'])\n",
    "results_df['FINAL'] = results_df[['y_pred1','y_pred2']].mean(axis=1)\n",
    "\n",
    "X_test_2['LAG_7'] = results_df['FINAL'].values\n",
    "\n",
    "y_pred1_2 = model1.predict(X_test_2[best_vars])\n",
    "y_pred2_2 = model2.predict(X_test_2[best_vars])\n",
    "\n",
    "results_df_2 = pd.DataFrame.from_dict({'ID':test_2['ID'].values, \n",
    "                                     'DATE':test_2['DATE'].values,\n",
    "                                     'y_pred1':y_pred1,\n",
    "                                     'y_pred2':y_pred2})\n",
    "results_df_2 = results_df_2.sort_values(['ID','DATE'])\n",
    "results_df_2['FINAL'] = results_df_2[['y_pred1','y_pred2']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc1798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.concat([results_df, results_df_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58149091",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ESTO HAY QUE HACERLO MÁS LIMPIO 100%\n",
    "start_date = datetime.date(2020, 1 , 18)\n",
    "end_date = datetime.date(2020, 1, 31)\n",
    "fechas_test = get_date_range(start_date, end_date)\n",
    "\n",
    "final_df = pd.DataFrame(columns=['ID','Dia_1','Dia_2','Dia_3','Dia_4','Dia_5','Dia_6','Dia_7'], index=range(2653))\n",
    "\n",
    "final_df['ID'] = results_df[results_df['DATE']==fechas_test[0]]['ID'].values\n",
    "final_df['Dia_1'] = results_df[results_df['DATE']==fechas_test[0]]['FINAL'].values\n",
    "final_df['Dia_2'] = results_df[results_df['DATE']==fechas_test[1]]['FINAL'].values\n",
    "final_df['Dia_3'] = results_df[results_df['DATE']==fechas_test[2]]['FINAL'].values\n",
    "final_df['Dia_4'] = results_df[results_df['DATE']==fechas_test[3]]['FINAL'].values\n",
    "final_df['Dia_5'] = results_df[results_df['DATE']==fechas_test[4]]['FINAL'].values\n",
    "final_df['Dia_6'] = results_df[results_df['DATE']==fechas_test[5]]['FINAL'].values\n",
    "final_df['Dia_7'] = results_df[results_df['DATE']==fechas_test[6]]['FINAL'].values\n",
    "final_df['Semana_1'] = final_df[['Dia_1','Dia_2','Dia_3','Dia_4','Dia_5','Dia_6','Dia_7']].sum(axis=1)\n",
    "\n",
    "ID = []\n",
    "Dia_8 = []\n",
    "Dia_9 = []\n",
    "Dia_10 = []\n",
    "Dia_11 = []\n",
    "Dia_12 = []\n",
    "Dia_13 = []\n",
    "Dia_14 = []\n",
    "for i, fecha in enumerate(fechas_test[7:14]):\n",
    "    aux = results_df[results_df['DATE']==fecha]\n",
    "    ID = list(aux['ID'].values)\n",
    "    if i==0:\n",
    "        Dia_8 += list(aux['FINAL'].values)\n",
    "    if i==1:\n",
    "        Dia_9 += list(aux['FINAL'].values)\n",
    "    if i==2:\n",
    "        Dia_10 += list(aux['FINAL'].values)\n",
    "    if i==3:\n",
    "        Dia_11 += list(aux['FINAL'].values)\n",
    "    if i==4:\n",
    "        Dia_12 += list(aux['FINAL'].values)\n",
    "    if i==5:\n",
    "        Dia_13 += list(aux['FINAL'].values)\n",
    "    if i==6:\n",
    "        Dia_14 += list(aux['FINAL'].values)\n",
    "print(len(ID),len(Dia_11))\n",
    "final_df2 = pd.DataFrame.from_dict({'ID':ID,\n",
    "                                   'Dia_8':Dia_8,\n",
    "                                  'Dia_9':Dia_9,\n",
    "                                  'Dia_10':Dia_10,\n",
    "                                  'Dia_11':Dia_11,\n",
    "                                  'Dia_12':Dia_12,\n",
    "                                  'Dia_13':Dia_13,\n",
    "                                  'Dia_14':Dia_14,})\n",
    "\n",
    "final_df['Semana_1'] = final_df[['Dia_1','Dia_2','Dia_3','Dia_4','Dia_5','Dia_6','Dia_7']].sum(axis=1)\n",
    "final_df['Semana_2'] = final_df2[['Dia_8','Dia_9','Dia_10','Dia_11','Dia_12','Dia_13','Dia_14']].sum(axis=1)\n",
    "\n",
    "final_df2 = final_df.drop('ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad418f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_pickle('../data/test.pkl')\n",
    "error = compute_error(final_df2, test)\n",
    "print('Mean between XGBR and GBR:', round(error,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d24a72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e79e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de05923b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.date(2020, 1 , 18)\n",
    "end_date = datetime.date(2020, 1, 31)\n",
    "fechas_test = get_date_range(start_date, end_date)\n",
    "\n",
    "results_df[results_df['DATE']==fechas_test[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762dcea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.date(2020, 1 , 18)\n",
    "end_date = datetime.date(2020, 1, 31)\n",
    "fechas_test = get_date_range(start_date, end_date)\n",
    "\n",
    "final_df = pd.DataFrame(columns=['ID','Dia_1','Dia_2','Dia_3','Dia_4','Dia_5','Dia_6','Dia_7'], index=range(2653))\n",
    "\n",
    "final_df['ID'] = results_df[results_df['DATE']==fechas_test[0]]['ID'].values\n",
    "final_df['Dia_1'] = results_df[results_df['DATE']==fechas_test[0]]['FINAL'].values\n",
    "final_df['Dia_2'] = results_df[results_df['DATE']==fechas_test[1]]['FINAL'].values\n",
    "final_df['Dia_3'] = results_df[results_df['DATE']==fechas_test[2]]['FINAL'].values\n",
    "final_df['Dia_4'] = results_df[results_df['DATE']==fechas_test[3]]['FINAL'].values\n",
    "final_df['Dia_5'] = results_df[results_df['DATE']==fechas_test[4]]['FINAL'].values\n",
    "final_df['Dia_6'] = results_df[results_df['DATE']==fechas_test[5]]['FINAL'].values\n",
    "final_df['Dia_7'] = results_df[results_df['DATE']==fechas_test[6]]['FINAL'].values\n",
    "final_df['Semana_1'] = final_df[['Dia_1','Dia_2','Dia_3','Dia_4','Dia_5','Dia_6','Dia_7']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d721ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
