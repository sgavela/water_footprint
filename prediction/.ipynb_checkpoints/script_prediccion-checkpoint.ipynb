{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5074b85f",
   "metadata": {},
   "source": [
    "# Script de predicción "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7a88ac",
   "metadata": {},
   "source": [
    "### Índice   \n",
    "1. [Carga de datos](#id1)\n",
    "\n",
    "    1.1 [Valores nulos en los datos](#id11)\n",
    "    \n",
    "    1.2 [Las columnas READINGTHOUSANTH y DELTATHOUSANDTH](#id12)\n",
    "    \n",
    "    1.3 [La columna SAMPLETIME](#id13)\n",
    "    \n",
    "   \n",
    "2. [Procesado de datos: las columnas DELTA y READING](#id2)\n",
    "\n",
    "    2.1 [Agregar los consumos por fechas](#id21)\n",
    "    \n",
    "    2.2 [Completar los consumos faltantes](#id22)\n",
    "    \n",
    "    2.3 [Tipos de contadores según su serie temporal de consumos](#id23)\n",
    "    \n",
    "    2.4 [Tratar outliers en los consumos y medidas negativas](#id24)\n",
    "    \n",
    "    \n",
    "3. [Predicciones contadores tipos 0, 1 y 3](#id3)\n",
    "\n",
    "    3.1 [Tipo 0](#id31)\n",
    "    \n",
    "    3.2 [Tipo 1](#id32)\n",
    "    \n",
    "    3.3 [Tipo 3](#id33)\n",
    "    \n",
    "    3.4 [Tipo 2](#id34)\n",
    "    \n",
    "4. [Predicciones contadores tipo 2](#id4)\n",
    "    \n",
    "    \n",
    "5. [Postprocesado](#id5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "12fd2bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f181b05d",
   "metadata": {},
   "source": [
    "## Carga de datos<a name=\"id1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3483bea",
   "metadata": {},
   "source": [
    "Cargamos los datos y observamos que tenemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e859c0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SAMPLETIME</th>\n",
       "      <th>READINGINTEGER</th>\n",
       "      <th>READINGTHOUSANDTH</th>\n",
       "      <th>DELTAINTEGER</th>\n",
       "      <th>DELTATHOUSANDTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-06-13 08:34:09</td>\n",
       "      <td>369320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-06-13 17:34:10</td>\n",
       "      <td>369403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-06-13 18:34:10</td>\n",
       "      <td>369403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-06-13 04:34:10</td>\n",
       "      <td>369284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-06-13 14:34:10</td>\n",
       "      <td>369356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID           SAMPLETIME  READINGINTEGER  READINGTHOUSANDTH  DELTAINTEGER  \\\n",
       "0   0  2019-06-13 08:34:09          369320                0.0            17   \n",
       "1   0  2019-06-13 17:34:10          369403                0.0             2   \n",
       "2   0  2019-06-13 18:34:10          369403                0.0             0   \n",
       "3   0  2019-06-13 04:34:10          369284                0.0             1   \n",
       "4   0  2019-06-13 14:34:10          369356                0.0            28   \n",
       "\n",
       "   DELTATHOUSANDTH  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              0.0  \n",
       "4              0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/Modelar_UH2022.txt',sep = '|') \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5901f7",
   "metadata": {},
   "source": [
    "Vemos el tamaño de los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a992035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21404828, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f66efe",
   "metadata": {},
   "source": [
    "### Valores nulos en los datos<a name=\"id11\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e8a0bf",
   "metadata": {},
   "source": [
    "Vemos si hay valores nulos en los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2c74d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                        0\n",
       "SAMPLETIME                0\n",
       "READINGINTEGER            0\n",
       "READINGTHOUSANDTH    140056\n",
       "DELTAINTEGER              0\n",
       "DELTATHOUSANDTH      140056\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88408cd1",
   "metadata": {},
   "source": [
    "Como los valores nulos pertenecen a la parte de las milésimas los despreciamos y los imputamos a 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d25f4c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f30d05",
   "metadata": {},
   "source": [
    "### Las columnas READINGTHOUSANDTH y DELTATHOUSANDTH<a name=\"id12\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602a1508",
   "metadata": {},
   "source": [
    "Examinemos las columnas READINGTHOUSANDTH y DELTATHOUSANDTH:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f6dab02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number READINGTHOUSANTH != 0: 2428718\n",
      "Number DELTATHOUSANTH != 0: 2428718\n",
      "Minimum READINGTHOUSANTH: 0.0\n",
      "Minimum DELTATHOUSANTH: 0.0\n",
      "Maximum READINGTHOUSANTH: 99.0\n",
      "Maximum DELTATHOUSANTH: 99.0\n"
     ]
    }
   ],
   "source": [
    "print('Number READINGTHOUSANTH != 0:',(df['READINGTHOUSANDTH']!=0).sum())\n",
    "print('Number DELTATHOUSANTH != 0:',(df['READINGTHOUSANDTH']!=0).sum())\n",
    "print('Minimum READINGTHOUSANTH:',df['READINGTHOUSANDTH'].min())\n",
    "print('Minimum DELTATHOUSANTH:',df['DELTATHOUSANDTH'].min())\n",
    "print('Maximum READINGTHOUSANTH:',df['READINGTHOUSANDTH'].max())\n",
    "print('Maximum DELTATHOUSANTH:',df['DELTATHOUSANDTH'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda17379",
   "metadata": {},
   "source": [
    "Aunque el valor máximo para estas columnas es 99, el nombre 'Thousandth' deja claro que estas columnas hacen referencia a las milésimas por lo que dividiremos su valor entre 1000 y se lo agregaremos a la parte de las unidades. No obstante, no creemos que estas dos columnas vayan a tener un gran impacto en las predicciones ya que como máximo estaremos añadiendo 0,099 litros a la medición.\n",
    "\n",
    "Tras agregarlo a las columnas de las unidades nos desharemos tanto de las columnas de las unidades como de las de las milésimas, quedándonos con el agregado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9ca9078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SAMPLETIME</th>\n",
       "      <th>DELTA</th>\n",
       "      <th>READING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-06-13 08:34:09</td>\n",
       "      <td>17.0</td>\n",
       "      <td>369320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-06-13 17:34:10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>369403.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-06-13 18:34:10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>369403.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-06-13 04:34:10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>369284.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-06-13 14:34:10</td>\n",
       "      <td>28.0</td>\n",
       "      <td>369356.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID           SAMPLETIME  DELTA   READING\n",
       "0   0  2019-06-13 08:34:09   17.0  369320.0\n",
       "1   0  2019-06-13 17:34:10    2.0  369403.0\n",
       "2   0  2019-06-13 18:34:10    0.0  369403.0\n",
       "3   0  2019-06-13 04:34:10    1.0  369284.0\n",
       "4   0  2019-06-13 14:34:10   28.0  369356.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['DELTA'] = [j+(i/1000) for (j,i) in zip(df['DELTAINTEGER'].values, df['DELTATHOUSANDTH'].values)]\n",
    "df['READING'] = [j+(i/1000) for (j,i) in zip(df['READINGINTEGER'].values, df['READINGTHOUSANDTH'].values)]\n",
    "df.drop(['READINGINTEGER','READINGTHOUSANDTH','DELTAINTEGER','DELTATHOUSANDTH'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7ad40f",
   "metadata": {},
   "source": [
    "### La columna SAMPLETIME<a name=\"id13\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5131d56c",
   "metadata": {},
   "source": [
    "La columna SAMPLETIME hace referencia al día y la hora a la que las medidas READING y DELTA fueron tomadas. Para poder trabajar comodamente con esta columna vamos a convertirla de tipo *string* a tipo *datetime* y a extraer de ella una nueva columna *DATE* en la que solo tendremos la fecha de la medida (sin la hora)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7959fbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fecha(date):\n",
    "    return date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "def str2date(string):\n",
    "    return datetime.datetime.strptime(string, '%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a85d84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 21404828/21404828 [10:14<00:00, 34829.19it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 21404828/21404828 [05:06<00:00, 69813.81it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SAMPLETIME</th>\n",
       "      <th>DELTA</th>\n",
       "      <th>READING</th>\n",
       "      <th>DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-06-13 08:34:09</td>\n",
       "      <td>17.0</td>\n",
       "      <td>369320.0</td>\n",
       "      <td>2019-06-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-06-13 17:34:10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>369403.0</td>\n",
       "      <td>2019-06-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-06-13 18:34:10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>369403.0</td>\n",
       "      <td>2019-06-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-06-13 04:34:10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>369284.0</td>\n",
       "      <td>2019-06-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-06-13 14:34:10</td>\n",
       "      <td>28.0</td>\n",
       "      <td>369356.0</td>\n",
       "      <td>2019-06-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID          SAMPLETIME  DELTA   READING        DATE\n",
       "0   0 2019-06-13 08:34:09   17.0  369320.0  2019-06-13\n",
       "1   0 2019-06-13 17:34:10    2.0  369403.0  2019-06-13\n",
       "2   0 2019-06-13 18:34:10    0.0  369403.0  2019-06-13\n",
       "3   0 2019-06-13 04:34:10    1.0  369284.0  2019-06-13\n",
       "4   0 2019-06-13 14:34:10   28.0  369356.0  2019-06-13"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "df['SAMPLETIME'] = df['SAMPLETIME'].progress_apply(str2date)\n",
    "df['DATE'] = df['SAMPLETIME'].progress_apply(get_fecha)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afb5d22",
   "metadata": {},
   "source": [
    "Antes de continuar ordenamos el dataframe por *ID* y *SAMPLETIME* para que sea más interpretable que si está desordenado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a97bad7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(['ID','SAMPLETIME']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229bdd01",
   "metadata": {},
   "source": [
    "## Procesado de datos: las columnas DELTA y READING<a name=\"id2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a68fe5f",
   "metadata": {},
   "source": [
    "Antes de empezar con el tratamiento de las columnas DELTA y READING hay que resaltar que la mayoría de las decisiones que vamos a tomar en este apartado están justificadas por las conclusiones obtenidas en el script de exploración por lo que no nos detendremos a explicar como hemos llegado a ellas (para ello mejor ver el script de exploración)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff81d9ce",
   "metadata": {},
   "source": [
    "En primer lugar vamos a definir una función que dadas dos fechas nos devuelva una lista de todas las fechas intermedias. Está función será una utilidad que emplearemos múltiples veces a lo largo de este notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba48e3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "given a start date in datetime format \"start_date\" and an \"end_date\" returns a list of strings with the dates from\n",
    "\"start_date\" to \"end_date\".\n",
    "\n",
    "Example:\n",
    "\n",
    "start_date = datetime.date(2019, 9 , 30)\n",
    "end_date = datetime.date(2019, 10, 7)\n",
    "get_date_range(start_date, end_date)\n",
    "'''\n",
    "def get_date_range(start_date, end_date):\n",
    "    number_of_days = (end_date-start_date).days\n",
    "    return [(start_date + datetime.timedelta(days = day)).isoformat() for day in range(number_of_days+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50efd4d",
   "metadata": {},
   "source": [
    "### Agregar los consumos por fechas<a name=\"id21\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8826d7",
   "metadata": {},
   "source": [
    "En este punto el primer paso claro a dar es agregar por fecha los consumos. No obstante nos encontramos con un serio problema: faltan muchas medidas. Para solventar esto vamos a hacer uso de las dos columnas *DELTA* y *READING*. En un principio si todos los datos están correctos consideramos que READING es más fiable. De no ser así, recurrimos a DELTA para tratar de completar los datos. Seguiremos el siguiente algoritmo:\n",
    "\n",
    "- IF no hay ninguna medida para un día:\n",
    "    * De momento lo dejamos como **NONE** y lo completaremos más adelante\n",
    "- IF hay 24 medidas, es decir, está completo:\n",
    "    * IF hay 24 medidas para el día anterior:\n",
    "        + Tomamos $max(READING_{actual})-max(READING_{anterior})$ \n",
    "    * IF no hay 24 medidas para el día anterior, es decir, está incompleto:\n",
    "        + Tomamos $sum(DELTA_{actual})$\n",
    "- IF no hay 24 medidas, es decir, está incompleto\n",
    "    * Tomamos $24/N_{medidas}*sum(DELTA_{actual})$, es decir, calculamos el promedio de las medidas que haya y lo múltiplicamos por 24 (como si hubiese 24 medidas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e964c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2747/2747 [02:17<00:00, 19.91it/s]\n"
     ]
    }
   ],
   "source": [
    "start_date = datetime.date(2019, 2 , 1)\n",
    "end_date = datetime.date(2020, 1, 31)\n",
    "complete_year = get_date_range(start_date, end_date)\n",
    "\n",
    "delta_df = pd.DataFrame(columns=df['ID'].unique(), index =complete_year)\n",
    "\n",
    "#primero rellenamos la primera columna\n",
    "date = complete_year[0]\n",
    "for i in tqdm(df['ID'].unique()):\n",
    "    one_counter = df[df['ID']==i]\n",
    "    # si no hay ninguna medida\n",
    "    if len(one_counter[one_counter['DATE']==date]) == 0:\n",
    "        delta_df[i][date] = None\n",
    "    # si el contador está completo para ese dia\n",
    "    elif len(one_counter[one_counter['DATE']==date]) >= 24:\n",
    "        delta_df[i][date] = one_counter[one_counter['DATE']==date]['DELTA'].sum()\n",
    "    # si el contador no está completo para ese dia\n",
    "    else:\n",
    "        delta_df[i][date] = (24/len(one_counter[one_counter['DATE']==date])) * \\\n",
    "                         one_counter[one_counter['DATE']==date]['DELTA'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "199457a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2747/2747 [2:07:09<00:00,  2.78s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(df['ID'].unique()):\n",
    "    one_counter = df[df['ID']==i]\n",
    "    for j in range(1, len(complete_year)):\n",
    "        date = complete_year[j]\n",
    "        # si no hay ninguna medida\n",
    "        if len(one_counter[one_counter['DATE']==date]) == 0:\n",
    "            delta_df[i][date] = None\n",
    "        # si el contador está completo para ese dia\n",
    "        elif len(one_counter[one_counter['DATE']==date]) >= 24:\n",
    "            # si el contador está completo para el dia anterior\n",
    "            if len(one_counter[one_counter['DATE']==complete_year[j-1]]) >= 24:\n",
    "                delta_df[i][date] = one_counter[one_counter['DATE']==complete_year[j]]['READING'].max() - \\\n",
    "                                    one_counter[one_counter['DATE']==complete_year[j-1]]['READING'].max()\n",
    "            # si el contador no está completo para el dia anterior\n",
    "            else:\n",
    "                delta_df[i][date] = one_counter[one_counter['DATE']==date]['DELTA'].sum()\n",
    "        # si el contador no está completo para ese dia\n",
    "        else:\n",
    "            delta_df[i][date] = (24/len(one_counter[one_counter['DATE']==date])) * \\\n",
    "                             one_counter[one_counter['DATE']==date]['DELTA'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0dc13b",
   "metadata": {},
   "source": [
    "Tras aplicar este algoritmo nos quedamos con un dataframe en el que hemos completado todos los días para los que había al menos 1 medida. Sin embargo, los días para los que no había ninguna medida siguen siendo **NONE**. Por lo que necesitaremos otras estrategias para completarlos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d964f4",
   "metadata": {},
   "source": [
    "### Completar medidas faltantes<a name=\"id22\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c7e14e",
   "metadata": {},
   "source": [
    "Empezaremos por completar los **NONE** comprendidos entre dos días para los cuales sí se tienen medidas, es decir, que no están ni al principio ni al final de la serie temporal. Para ello tomaremos la última medida *READING* del día en el que empieza la secuencia de **NONE** y la primera medida *READING* del día que termina la secuencia. Si restamos estas dos medidas obtendremos el consumo de agua total durante los días sin medidas, es decir, durante la secuencia de **NONE**. Para interpolar entre estas dos medidas dividiremos este consumo total entre el número de días sin medidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6561d8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_df.to_pickle('../data/counters_in_rows_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3c2436ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_huecos(deltas, readings):\n",
    "    consecutive_nones = 0\n",
    "    last_date_not_none = None\n",
    "    none_dates = []\n",
    "    for date in deltas.index:\n",
    "        if deltas[date] == None:\n",
    "            consecutive_nones += 1\n",
    "            none_dates.append(date)\n",
    "        elif deltas[date] != None:\n",
    "            if consecutive_nones > 0:\n",
    "                begin = readings[readings['DATE']==last_date_not_none]['READING'].max()\n",
    "                end = readings[readings['DATE']==date]['READING'].min()\n",
    "                for date_2 in none_dates:\n",
    "                    deltas[date_2] = (end-begin)/consecutive_nones\n",
    "            consecutive_nones = 0\n",
    "            last_date_not_none = date  \n",
    "            none_dates = []\n",
    "    return deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "144b0ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2747/2747 [17:44<00:00,  2.58it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(df['ID'].unique()): \n",
    "    delta_df[i] = complete_huecos(delta_df[i], df[df['ID']==i][['DATE', 'READING']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c57d1a0",
   "metadata": {},
   "source": [
    "### Tipos de contadores según su serie temporal de consumos<a name=\"id23\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248b88ad",
   "metadata": {},
   "source": [
    "Tras este procesado tenemos tres tipos de contadores:\n",
    "- Contadores completos\n",
    "- Contadores a los que les faltan medidas al principio\n",
    "- Contadores a los que les faltan medidas al final\n",
    "- Contadores a los que les faltan medidas al principo y al final\n",
    "\n",
    "Vamos a dividir de manera más formal los contadores en tipos según su serie temporal de consumos:\n",
    "- **Tipo 1:** Contadores cuyas medidas sean todas 0.\n",
    "- **Tipo 2:** Contadores completos al menos en Enero de 2020 no pertenecientes al Tipo 1.\n",
    "- **Tipo 3:** Contadores sin medidas en Noviembre, Diciembre de 2019 y Enero de 2020 pero con medidas en Febrero de 2019 no pertenecientes al Tipo 1.\n",
    "- **Tipo 0:** Contadores no pertencientes a ninguno de los anteriores tipos.\n",
    "\n",
    "Esta división es muy importante ya que dependiendo del tipo del contador se le aplicará una estrategia de predicción u otra. A continuación vamos a fabricar un diccionario en el cual las claves sean los identificadores de los 4 tipos y los valores listas con los IDs pertenecientes a ese tipo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "562eedbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2747/2747 [00:00<00:00, 3606.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tipo_1: 68\n",
      "tipo_2: 2535\n",
      "tipo_3: 44\n",
      "tipo_0: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dicc_tipos = {'tipo_1':[], 'tipo_2':[], 'tipo_3':[], 'tipo_0':[]}\n",
    "\n",
    "for i in tqdm(delta_df.columns):\n",
    "    if delta_df[i].sum()==0:\n",
    "        dicc_tipos['tipo_1'].append(i)\n",
    "    elif delta_df[i][delta_df[i].index >= '2020-01-01'].isna().sum()==0:\n",
    "        dicc_tipos['tipo_2'].append(i)\n",
    "    elif delta_df[i][delta_df[i].index <= '2019-02-14'].isna().sum()==0:\n",
    "        dicc_tipos['tipo_3'].append(i)\n",
    "    else:\n",
    "        dicc_tipos['tipo_0'].append(i)\n",
    "        \n",
    "for t in dicc_tipos:\n",
    "    print(t+':', len(dicc_tipos[t]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c8a9c8",
   "metadata": {},
   "source": [
    "### Tratar outliers en los consumos y medidas negativas<a name=\"id24\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769524ae",
   "metadata": {},
   "source": [
    "El propósito de esta sección es tratar los outliers en las series temporales de cada contador. Para ello recorrermos todos los contadores en busca de outliers. Consideraremos un outlier cualquier medida *DELTA* tal que\n",
    "\n",
    "$DELTA > Q_3 + IQR \\\\ ó  \\\\ DELTA < Q_1 - IQR$\n",
    "\n",
    "donde $Q_1$ y $Q_3$ son el primer y tercer cuartil respectivamente y $IQR$ es el rango intercuartílico. Transformaremos estos outliers igualándolos a la media de consumos del contador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "f85d531f",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_df = pd.read_pickle('../data/counters_in_rows_3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "640865ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_df.fillna(value=np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "550ea65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_outliers(delta_serie, IQR, Q1, Q3, avg):\n",
    "    values = delta_serie.values\n",
    "    out = []\n",
    "    for delta in values:\n",
    "        if not np.isnan(delta) and (delta < Q1 - 1.5*IQR or delta > Q3 + 1.5*IQR):\n",
    "            out.append(avg)\n",
    "        else:\n",
    "            out.append(delta)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "15b324bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2747/2747 [00:04<00:00, 627.04it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(delta_df.columns):\n",
    "    Q1 = np.percentile(delta_df[i][delta_df[i].notna()], 25, method = 'midpoint')\n",
    "    Q3 = np.percentile(delta_df[i][delta_df[i].notna()], 75, method = 'midpoint')\n",
    "    IQR = Q3 - Q1\n",
    "    avg = np.mean(delta_df[i][delta_df[i].notna()])\n",
    "    delta_df[i] = replace_outliers(delta_df[i], IQR, Q1, Q3, avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84633c81",
   "metadata": {},
   "source": [
    "Por otro lado, no tiene ningún sentido que un dato de consumo sea negativo. Si los datos fuesen perfectos esto no pasaría, pero no es el caso y a pesar de los tratamientos que hemos hecho hasta ahora sigue habiendo algunos consumos negativos. Sencillamente transformaremos estos consumos en ceros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "6151282f",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_df[delta_df < 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8e1b79",
   "metadata": {},
   "source": [
    "## Predicciones contadores tipos 0, 1 y 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b571cc96",
   "metadata": {},
   "source": [
    "El propósito de esta sección es hacer predicciones de consumo para las dos primeras semanas de Febrero de 2020 para cada contador de los tipos 0, 1 y 3. Según el tipo del contador emplearemos estrategias más o menos sofisiticadas. Recordemos cuantos contadores hay de cada tipo:\n",
    "\n",
    "- Tipo 1: 68\n",
    "- Tipo 2: 2535\n",
    "- Tipo 3: 44\n",
    "- Tipo 0: 100\n",
    "\n",
    "Nuestros mayores esfuerzos estarán volcados en los contadores de Tipo 2 que tendrán una sección propia, ya que la inmensa mayoría de contadores son de este tipo y además son los más completos. Para ir recopilando las predicciones nos ayudaremos de un DataFrame *results_df* que iremos completando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "8fa3b1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.date(2020, 2 , 1)\n",
    "end_date = datetime.date(2020, 2, 14)\n",
    "prediction_dates = get_date_range(start_date, end_date)\n",
    "\n",
    "results_df = pd.DataFrame(columns = delta_df.columns, index = prediction_dates)\n",
    "results_df2 = pd.DataFrame(columns = delta_df.columns, index = prediction_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b5c7ad",
   "metadata": {},
   "source": [
    "### Tipo 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2d53b1",
   "metadata": {},
   "source": [
    "Los contadores de tipo 0 o bien no tienen medidas en Enero de 2020 ni en Febrero de 2019, o bien tienen muy pocas. En cualquier caso son contadores muy difíciles de predecir ya que no tenemos la cantidad apropiada de datos y en el caso de que sí la tengamos son datos poco relevantes (como los consumos de Junio). \n",
    "\n",
    "En este caso hemos considerado que la mejor opción es hacer una estimación grosera. Para el contador $i$ y fecha $j$ se predecirá:\n",
    "\n",
    "$PREDICTION_{i, j}=\\frac{3}{4}\\cdot avg(DELTA_{i}) + \\frac{1}{4}\\cdot \\beta_j$\n",
    "\n",
    "donde $avg(DELTA_{i})$ es la media de consumos del contador $i$ y $\\beta_j$ es la media de consumos de los contadores tipo 2 en la fecha $j$ en 2019.\n",
    "\n",
    "La idea inicial es predecir siempre la media de consumos del contador $i$. No obstante, esta media puede ser engañosa ya que está hecha a partir de pocos datos o datos poco relevantes. Por lo que la corregimos usando la media de consumos en Febrero de 2019 en el dia $j$ para los contadores que sí tenemos ese dato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "4bdf11d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2019-02-01',\n",
       " '2019-02-02',\n",
       " '2019-02-03',\n",
       " '2019-02-04',\n",
       " '2019-02-05',\n",
       " '2019-02-06',\n",
       " '2019-02-07',\n",
       " '2019-02-08',\n",
       " '2019-02-09',\n",
       " '2019-02-10',\n",
       " '2019-02-11',\n",
       " '2019-02-12',\n",
       " '2019-02-13',\n",
       " '2019-02-14']"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "february_2019_two_weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "cfd34413",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:09<00:00, 10.57it/s]\n"
     ]
    }
   ],
   "source": [
    "start_date = datetime.date(2019, 2 , 1)\n",
    "end_date = datetime.date(2019, 2, 14)\n",
    "february_2019_two_weeks = get_date_range(start_date, end_date)\n",
    "\n",
    "for i in tqdm(dicc_tipos['tipo_0']):\n",
    "    predictions = []\n",
    "    avg_delta = np.mean(delta_df[i][delta_df[i].notna()])\n",
    "    for date in february_2019_two_weeks:\n",
    "        beta = delta_df[dicc_tipos['tipo_2']].dropna(axis=1)[delta_df.index <= '2019-02-14'].mean(axis=1)[date]\n",
    "        predictions.append(3/4*avg_delta + 1/4*beta)\n",
    "    results_df[i] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "a233882b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020-01-30    8.7\n",
       "2020-01-31    8.7\n",
       "Name: 2739, dtype: float64"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_df[2739][delta_df[2739].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "36814b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020-02-01    8.7\n",
       "2020-02-02    8.7\n",
       "2020-02-03    8.7\n",
       "2020-02-04    8.7\n",
       "2020-02-05    8.7\n",
       "2020-02-06    8.7\n",
       "2020-02-07    8.7\n",
       "2020-02-08    8.7\n",
       "2020-02-09    8.7\n",
       "2020-02-10    8.7\n",
       "2020-02-11    8.7\n",
       "2020-02-12    8.7\n",
       "2020-02-13    8.7\n",
       "2020-02-14    8.7\n",
       "Name: 2739, dtype: float64"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[2739]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "7d5082bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020-02-01    8.7\n",
       "2020-02-02    8.7\n",
       "2020-02-03    8.7\n",
       "2020-02-04    8.7\n",
       "2020-02-05    8.7\n",
       "2020-02-06    8.7\n",
       "2020-02-07    8.7\n",
       "2020-02-08    8.7\n",
       "2020-02-09    8.7\n",
       "2020-02-10    8.7\n",
       "2020-02-11    8.7\n",
       "2020-02-12    8.7\n",
       "2020-02-13    8.7\n",
       "2020-02-14    8.7\n",
       "Name: 2739, dtype: float64"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[2739]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "70565330",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:09<00:00, 10.40it/s]\n"
     ]
    }
   ],
   "source": [
    "start_date = datetime.date(2019, 2 , 1)\n",
    "end_date = datetime.date(2019, 2, 14)\n",
    "february_2019_two_weeks = get_date_range(start_date, end_date)\n",
    "\n",
    "for i in tqdm(dicc_tipos['tipo_0']):\n",
    "    predictions = []\n",
    "    avg_delta = np.mean(delta_df[i][delta_df[i].notna()])\n",
    "    for date in february_2019_two_weeks:\n",
    "        beta = delta_df[dicc_tipos['tipo_2']].dropna(axis=1)[delta_df.index <= '2019-02-14'].mean(axis=1)[date]\n",
    "        predictions.append(avg_delta)\n",
    "    results_df[i] = predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ae9ba1",
   "metadata": {},
   "source": [
    "### Tipo 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb6a40d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42304af5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42c31a77",
   "metadata": {},
   "source": [
    "### Tipo 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94172450",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
