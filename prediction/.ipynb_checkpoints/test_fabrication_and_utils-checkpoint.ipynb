{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook se construye un conjunto de test (básicamente este conjunto será la última semana de enero) y se proporcionan algunas utilidades:\n",
    "\n",
    "- Una función que dada una predicción la pase al formato apropiado para la entrega\n",
    "- Una función que dada una predicción devuelva la métrica sobre el conjunto empleado como test (que en este caso será la última semana de Enero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SAMPLETIME</th>\n",
       "      <th>DELTA</th>\n",
       "      <th>READING</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-06-13 08:34:09</td>\n",
       "      <td>17.0</td>\n",
       "      <td>369320.0</td>\n",
       "      <td>2019-06-13</td>\n",
       "      <td>08:34:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-06-13 17:34:10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>369403.0</td>\n",
       "      <td>2019-06-13</td>\n",
       "      <td>17:34:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-06-13 18:34:10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>369403.0</td>\n",
       "      <td>2019-06-13</td>\n",
       "      <td>18:34:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-06-13 04:34:10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>369284.0</td>\n",
       "      <td>2019-06-13</td>\n",
       "      <td>04:34:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-06-13 14:34:10</td>\n",
       "      <td>28.0</td>\n",
       "      <td>369356.0</td>\n",
       "      <td>2019-06-13</td>\n",
       "      <td>14:34:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID           SAMPLETIME  DELTA   READING        DATE      TIME\n",
       "0   0  2019-06-13 08:34:09   17.0  369320.0  2019-06-13  08:34:09\n",
       "1   0  2019-06-13 17:34:10    2.0  369403.0  2019-06-13  17:34:10\n",
       "2   0  2019-06-13 18:34:10    0.0  369403.0  2019-06-13  18:34:10\n",
       "3   0  2019-06-13 04:34:10    1.0  369284.0  2019-06-13  04:34:10\n",
       "4   0  2019-06-13 14:34:10   28.0  369356.0  2019-06-13  14:34:10"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('../data/data_v1.pkl') \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DATE</th>\n",
       "      <th>DELTA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>243.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-02</td>\n",
       "      <td>236.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-03</td>\n",
       "      <td>335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-04</td>\n",
       "      <td>252.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-05</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID        DATE  DELTA\n",
       "0   0  2019-02-01  243.0\n",
       "1   0  2019-02-02  236.0\n",
       "2   0  2019-02-03  335.0\n",
       "3   0  2019-02-04  252.0\n",
       "4   0  2019-02-05  220.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['SAMPLETIME','TIME','READING'],axis=1)\n",
    "df = df.groupby(['ID','DATE']).sum().reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "'''\n",
    "given a start date in datetime format \"start_date\" and an \"end_date\" returns a list of strings with the dates from\n",
    "\"start_date\" to \"end_date\".\n",
    "\n",
    "Example:\n",
    "\n",
    "start_date = datetime.date(2019, 9 , 30)\n",
    "end_date = datetime.date(2019, 10, 7)\n",
    "get_date_range(start_date, end_date)\n",
    "'''\n",
    "def get_date_range(start_date, end_date):\n",
    "    number_of_days = (end_date-start_date).days\n",
    "    return [(start_date + datetime.timedelta(days = day)).isoformat() for day in range(number_of_days+1)]\n",
    "\n",
    "'''\n",
    "given a df in which there is one or zero entries per ID and DATE, a start_date and an end date, returns a dictionary whose\n",
    "keys are ID and the days between start_date and end_date and whose values are a list of IDs for 'ID' key and a list of\n",
    "the DELTA values for each ID and DATE for the keys corresponding to the days between start_date and end_date. If for some \n",
    "ID and DATE there is no such DELTA, then we take DELTA=0. The execution takes so long due to the df filtering. \n",
    "\n",
    "Example:\n",
    "\n",
    "start_date = datetime.date(2019, 9 , 30)\n",
    "end_date = datetime.date(2019, 10, 7)\n",
    "get_set_by_days(df, start_date, end_date)\n",
    "'''\n",
    "def get_set_by_days(df, start_date, end_date):\n",
    "    list_of_days = get_date_range(start_date, end_date)\n",
    "    test_dict = {'ID':[]}\n",
    "    for i in tqdm(df['ID'].unique()):\n",
    "        test_dict['ID'].append(i)\n",
    "        for day in list_of_days:\n",
    "            filtered_df = df[(df['ID']==i) & (df['DATE']==day)]\n",
    "            #comprobar que no haya mas de una entrada por ID y DATE\n",
    "            if len(filtered_df)>1:\n",
    "                raise Exception(\"More than one delta value per ID and DATE\")\n",
    "            #si hay una entrada, añadimos el valor de delta\n",
    "            elif len(filtered_df)==1:\n",
    "                delta = filtered_df.iloc[0]['DELTA']\n",
    "                if day not in list(test_dict.keys()):\n",
    "                    test_dict[day] = [delta]\n",
    "                else:\n",
    "                    test_dict[day].append(delta)\n",
    "            #si no hay entrada añadimos 0 \n",
    "            else:\n",
    "                if day not in test_dict.keys():\n",
    "                    test_dict[day] = [None]\n",
    "                else:\n",
    "                    test_dict[day].append(None)\n",
    "    return test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 2747/2747 [16:11:46<00:00, 21.23s/it]\n"
     ]
    }
   ],
   "source": [
    "start_date = datetime.date(2019, 2 , 1)\n",
    "end_date = datetime.date(2020, 1, 31)\n",
    "training_dict = get_set_by_days(df, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_formated = pd.DataFrame.from_dict(training_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_formated.to_pickle(\"../data/counters_in_rows.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test fabrication and error computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2747/2747 [04:08<00:00, 11.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2747, 9)\n",
      "    2020-01-18  2020-01-19  2020-01-20  2020-01-21  2020-01-22  2020-01-23  \\\n",
      "ID                                                                           \n",
      "0        421.0       273.0       306.0       292.0       460.0       331.0   \n",
      "1          0.0       216.0        14.0         3.0         0.0         3.0   \n",
      "2         28.0        33.0        48.0        35.0        33.0        20.0   \n",
      "3        485.0       394.0       237.0       297.0       312.0       321.0   \n",
      "4        365.0       387.0       370.0       293.0       287.0       361.0   \n",
      "\n",
      "    2020-01-24  first_week  second_week  \n",
      "ID                                       \n",
      "0       368.00     2451.00      2222.00  \n",
      "1         5.67      241.67        54.33  \n",
      "2        37.00      234.00       272.00  \n",
      "3       439.00     2485.00      2792.00  \n",
      "4       203.00     2266.00      2216.00  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle('../data/df6.pkl') \n",
    "df=df[['ID','DELTA','DATE']]\n",
    "start_date = datetime.date(2020,  1, 18)\n",
    "end_date = datetime.date(2020, 1, 31)\n",
    "training_dict = get_set_by_days(df, start_date, end_date)\n",
    "test = pd.DataFrame.from_dict(training_dict)\n",
    "test.set_index('ID', inplace = True)\n",
    "\n",
    "start_date = datetime.date(2020, 1 , 18)\n",
    "end_date = datetime.date(2020, 1, 24)\n",
    "first_week = get_date_range(start_date, end_date)\n",
    "\n",
    "start_date = datetime.date(2020, 1 , 25)\n",
    "end_date = datetime.date(2020, 1, 31)\n",
    "second_week = get_date_range(start_date, end_date)\n",
    "\n",
    "test['first_week'] = test[first_week].sum(axis=1)\n",
    "test['second_week'] = test[second_week].sum(axis=1) \n",
    "\n",
    "test.drop(second_week, axis=1, inplace=True)\n",
    "print(test.shape)\n",
    "print(test.head())\n",
    "test.to_pickle('../data/test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function expects two dataframes with the same format: for the first seven columns, each column corresponds to a date \n",
    "and each row corresponds to a counter index. In position i,j there should be DELTA of counter i in date j. \n",
    "For the last two columns of the dataframes they should not reffer to a daily prediction but to the aggregated prediction \n",
    "of week_1 and week_2. Given these two dataframes (one for theprediction and one for the real values), \n",
    "the function returns de error according to the competition rules.\n",
    "\n",
    "Examples:\n",
    "\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "test = pd.read_pickle('../data/test.pkl')\n",
    "\n",
    "compute_error(test, test)\n",
    "\n",
    "test_v3 = copy.copy(test)\n",
    "test_v3.iloc[:,0] = test_v3.iloc[:,1]\n",
    "compute_error(test_v3, test)\n",
    "\n",
    "'''\n",
    "def compute_error(pred, real):\n",
    "    daily_rmses = []\n",
    "    for i in range(7):\n",
    "        daily_rmses.append((((real.iloc[:,i] - pred.iloc[:,i])**2/len(real.iloc[:,i])).sum())**(1/2))\n",
    "    rmse_1 = sum(daily_rmses)/7\n",
    "    \n",
    "    first_week_pred_sum = pred.iloc[:,7].sum()\n",
    "    second_week_pred_sum = pred.iloc[:,8].sum()\n",
    "    first_week_real_sum = real.iloc[:,7].sum()\n",
    "    second_week_real_sum = real.iloc[:,8].sum()\n",
    "    \n",
    "    first_week_rmse = (((first_week_real_sum - first_week_pred_sum)**2)/len(real.iloc[:,7]))**(1/2)\n",
    "    second_week_rmse = (((second_week_real_sum - second_week_pred_sum)**2)/len(real.iloc[:,8]))**(1/2)\n",
    "    rmse_2 = (first_week_rmse + second_week_rmse)/2\n",
    "    \n",
    "    return (rmse_1 + rmse_2)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This method expects one dataframe with a certain format: for the first seven columns, each column corresponds to a date \n",
    "and each row corresponds to a counter index. In position i,j there should be DELTA of counter i in date j. \n",
    "For the last two columns of the dataframes they should not reffer to a daily prediction but to the aggregated prediction \n",
    "of week_1 and week_2. It saves this dataframe into a txt file in the format according to the competition rules.\n",
    "\n",
    "DISCLAIMER:\n",
    "Although the dataframe is saved in csv format, it must be used .txt extension.\n",
    "'''\n",
    "def to_txt(pred, path = './data/predicition.txt'):\n",
    "    pred.to_csv(path, , sep = '|', header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a69ea4cfb8306203f039115af0465b6153b9707b088c28cf8f65bbadd28ca25a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
