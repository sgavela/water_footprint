{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0219175",
   "metadata": {},
   "source": [
    "En este notebook se recogen varias pruebas solo con los contadores cuyas series temporales son completas o casi completas.\n",
    "\n",
    "1. Predicci√≥n haciendo la media entre XGBoost Regressor y Gradient Boosting Regressor\n",
    "2. Modelos ARIMA para todas las series\n",
    "3. Ensemble entre ARIMA y XGBoost Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e724f8",
   "metadata": {},
   "source": [
    "### Imports, utils and train/test creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1cc91283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7de53133",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "42d9a071",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "given a start date in datetime format \"start_date\" and an \"end_date\" returns a list of strings with the dates from\n",
    "\"start_date\" to \"end_date\".\n",
    "\n",
    "Example:\n",
    "\n",
    "start_date = datetime.date(2019, 9 , 30)\n",
    "end_date = datetime.date(2019, 10, 7)\n",
    "get_date_range(start_date, end_date)\n",
    "'''\n",
    "def get_date_range(start_date, end_date):\n",
    "    number_of_days = (end_date-start_date).days\n",
    "    return [(start_date + datetime.timedelta(days = day)).isoformat() for day in range(number_of_days+1)]\n",
    "\n",
    "'''\n",
    "This function expects two dataframes with the same format: for the first seven columns, each column corresponds to a date \n",
    "and each row corresponds to a counter index. In position i,j there should be DELTA of counter i in date j. \n",
    "For the last two columns of the dataframes they should not reffer to a daily prediction but to the aggregated prediction \n",
    "of week_1 and week_2. Given these two dataframes (one for theprediction and one for the real values), \n",
    "the function returns de error according to the competition rules.\n",
    "\n",
    "Examples:\n",
    "\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "test = pd.read_pickle('../data/test.pkl')\n",
    "\n",
    "compute_error(test, test)\n",
    "\n",
    "test_v3 = copy.copy(test)\n",
    "test_v3.iloc[:,0] = test_v3.iloc[:,1]\n",
    "compute_error(test_v3, test)\n",
    "\n",
    "'''\n",
    "def compute_error(pred, real):\n",
    "    daily_rmses = []\n",
    "    for i in range(7):\n",
    "        daily_rmses.append((((real.iloc[:,i] - pred.iloc[:,i])**2/len(real.iloc[:,i])).sum())**(1/2))\n",
    "    rmse_1 = sum(daily_rmses)/7\n",
    "    \n",
    "    first_week_pred_sum = pred.iloc[:,7].sum()\n",
    "    second_week_pred_sum = pred.iloc[:,8].sum()\n",
    "    first_week_real_sum = real.iloc[:,7].sum()\n",
    "    second_week_real_sum = real.iloc[:,8].sum()\n",
    "    \n",
    "    first_week_rmse = (((first_week_real_sum - first_week_pred_sum)**2)/len(real.iloc[:,7]))**(1/2)\n",
    "    second_week_rmse = (((second_week_real_sum - second_week_pred_sum)**2)/len(real.iloc[:,8]))**(1/2)\n",
    "    rmse_2 = (first_week_rmse + second_week_rmse)/2\n",
    "    \n",
    "    return (rmse_1 + rmse_2)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5077e5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (964197, 14) Test: (38458, 15)\n"
     ]
    }
   ],
   "source": [
    "path = '../data/df6.pkl'\n",
    "\n",
    "df = pd.read_pickle(path)\n",
    "start_date = datetime.date(2019, 2 , 1)\n",
    "end_date = datetime.date(2020, 1, 17)\n",
    "train = df[df['DATE'].isin(get_date_range(start_date, end_date))]\n",
    "train.drop(['YEAR_DAY','WEEKDAY','IS_GOOD','DATE'], axis=1, inplace=True)\n",
    "train['SUN'] = train['SUN'].fillna(train['SUN'].mean())\n",
    "train['PRECIPITATIONS'] = train['PRECIPITATIONS'].fillna(train['PRECIPITATIONS'].mean())\n",
    "\n",
    "start_date = datetime.date(2020, 1 , 18)\n",
    "end_date = datetime.date(2020, 1, 31)\n",
    "test = df[df['DATE'].isin(get_date_range(start_date, end_date))]\n",
    "test.drop(['YEAR_DAY','WEEKDAY','IS_GOOD'], axis=1, inplace=True)\n",
    "test['SUN'] = test['SUN'].fillna(test['SUN'].mean())\n",
    "test['PRECIPITATIONS'] = test['PRECIPITATIONS'].fillna(test['PRECIPITATIONS'].mean())\n",
    "\n",
    "print('Train:', train.shape, 'Test:', test.shape)\n",
    "\n",
    "X_train = train.drop(['DELTA'], axis=1)\n",
    "y_train = train['DELTA']\n",
    "\n",
    "X_test = test.drop(['DELTA', 'DATE'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbeddfd",
   "metadata": {},
   "source": [
    "### XGBR and GBR for all counters\n",
    "\n",
    "- The final prediction is the mean between XGBR and GBR\n",
    "- No lags are used\n",
    "- The week prediction is done just by adding the daily predictions \n",
    "\n",
    "#### PROBAR LO MISMO PERO METIENDO LAG_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fca45058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting XGB...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting GB...\n",
      "End fitting.\n"
     ]
    }
   ],
   "source": [
    "model1 = xgb.XGBRegressor(\n",
    "    n_estimators=1000,\n",
    "    reg_lambda=1,\n",
    "    gamma=0,\n",
    "    max_depth=8\n",
    ")\n",
    "\n",
    "model2 = GradientBoostingRegressor()\n",
    "\n",
    "print('Fitting XGB...')\n",
    "model1.fit(X_train, y_train)\n",
    "print('Fitting GB...')\n",
    "model2.fit(X_train, y_train)\n",
    "print('End fitting.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a413d463",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = model1.predict(X_test)\n",
    "y_pred2 = model2.predict(X_test)\n",
    "\n",
    "results_df = pd.DataFrame.from_dict({'ID':test['ID'].values, \n",
    "                                     'DATE':test['DATE'].values,\n",
    "                                     'y_pred1':y_pred1,\n",
    "                                     'y_pred2':y_pred2})\n",
    "results_df = results_df.sort_values(['ID','DATE'])\n",
    "results_df['FINAL'] = results_df[['y_pred1','y_pred2']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b457027c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2747 2747\n",
      "2747 2747\n"
     ]
    }
   ],
   "source": [
    "start_date = datetime.date(2020, 1 , 18)\n",
    "end_date = datetime.date(2020, 1, 31)\n",
    "fechas_test = get_date_range(start_date, end_date)\n",
    "\n",
    "ID = []\n",
    "Dia_1 = []\n",
    "Dia_2 = []\n",
    "Dia_3 = []\n",
    "Dia_4 = []\n",
    "Dia_5 = []\n",
    "Dia_6 = []\n",
    "Dia_7 = []\n",
    "for i, fecha in enumerate(fechas_test[0:7]):\n",
    "    aux = results_df[results_df['DATE']==fecha]\n",
    "    ID = list(aux['ID'].values)\n",
    "    if i==0:\n",
    "        Dia_1 += list(aux['FINAL'].values)\n",
    "    if i==1:\n",
    "        Dia_2 += list(aux['FINAL'].values)\n",
    "    if i==2:\n",
    "        Dia_3 += list(aux['FINAL'].values)\n",
    "    if i==3:\n",
    "        Dia_4 += list(aux['FINAL'].values)\n",
    "    if i==4:\n",
    "        Dia_5 += list(aux['FINAL'].values)\n",
    "    if i==5:\n",
    "        Dia_6 += list(aux['FINAL'].values)\n",
    "    if i==6:\n",
    "        Dia_7 += list(aux['FINAL'].values)\n",
    "print(len(ID),len(Dia_1))\n",
    "final_df = pd.DataFrame.from_dict({'ID':ID,\n",
    "                                   'Dia_1':Dia_1,\n",
    "                                  'Dia_2':Dia_2,\n",
    "                                  'Dia_3':Dia_3,\n",
    "                                  'Dia_4':Dia_4,\n",
    "                                  'Dia_5':Dia_5,\n",
    "                                  'Dia_6':Dia_6,\n",
    "                                  'Dia_7':Dia_7,})\n",
    "\n",
    "ID = []\n",
    "Dia_8 = []\n",
    "Dia_9 = []\n",
    "Dia_10 = []\n",
    "Dia_11 = []\n",
    "Dia_12 = []\n",
    "Dia_13 = []\n",
    "Dia_14 = []\n",
    "for i, fecha in enumerate(fechas_test[7:14]):\n",
    "    aux = results_df[results_df['DATE']==fecha]\n",
    "    ID = list(aux['ID'].values)\n",
    "    if i==0:\n",
    "        Dia_8 += list(aux['FINAL'].values)\n",
    "    if i==1:\n",
    "        Dia_9 += list(aux['FINAL'].values)\n",
    "    if i==2:\n",
    "        Dia_10 += list(aux['FINAL'].values)\n",
    "    if i==3:\n",
    "        Dia_11 += list(aux['FINAL'].values)\n",
    "    if i==4:\n",
    "        Dia_12 += list(aux['FINAL'].values)\n",
    "    if i==5:\n",
    "        Dia_13 += list(aux['FINAL'].values)\n",
    "    if i==6:\n",
    "        Dia_14 += list(aux['FINAL'].values)\n",
    "print(len(ID),len(Dia_11))\n",
    "final_df2 = pd.DataFrame.from_dict({'ID':ID,\n",
    "                                   'Dia_8':Dia_8,\n",
    "                                  'Dia_9':Dia_9,\n",
    "                                  'Dia_10':Dia_10,\n",
    "                                  'Dia_11':Dia_11,\n",
    "                                  'Dia_12':Dia_12,\n",
    "                                  'Dia_13':Dia_13,\n",
    "                                  'Dia_14':Dia_14,})\n",
    "\n",
    "final_df['Semana_1'] = final_df[['Dia_1','Dia_2','Dia_3','Dia_4','Dia_5','Dia_6','Dia_7']].sum(axis=1)\n",
    "final_df['Semana_2'] = final_df2[['Dia_8','Dia_9','Dia_10','Dia_11','Dia_12','Dia_13','Dia_14']].sum(axis=1)\n",
    "\n",
    "final_df2 = final_df.drop('ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5c1ef959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean between XGBR and GBR: 21080.97\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_pickle('../data/test.pkl')\n",
    "error = compute_error(final_df2, test)\n",
    "print('Mean between XGBR and GBR:', round(error,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfc9722",
   "metadata": {},
   "source": [
    "### ARIMA for good counters, XGBR and GBR for bad ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68af448",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5355f4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bec5e90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
