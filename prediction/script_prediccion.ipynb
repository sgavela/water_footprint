{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59b50320",
   "metadata": {},
   "source": [
    "# Script de predicción "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21011205",
   "metadata": {},
   "source": [
    "### Índice   \n",
    "1. [Carga de datos](#id1)\n",
    "\n",
    "    1.1 [Valores nulos en los datos](#id11)\n",
    "    \n",
    "    1.2 [Las columnas READINGTHOUSANTH y DELTATHOUSANDTH](#id12)\n",
    "    \n",
    "    1.3 [La columna SAMPLETIME](#id13)\n",
    "    \n",
    "   \n",
    "2. [Procesado de datos: las columnas DELTA y READING](#id2)\n",
    "\n",
    "    2.1 [Agregar los consumos por fechas](#id21)\n",
    "    \n",
    "    2.2 [Completar medidas faltantes](#id22)\n",
    "    \n",
    "    2.3 [Tipos de contadores según su serie temporal de consumos](#id23)\n",
    "    \n",
    "    2.4 [Tratar outliers en los consumos y medidas negativas](#id24)\n",
    "    \n",
    "    \n",
    "3. [Predicciones contadores tipos 0, 1 y 3](#id3)\n",
    "\n",
    "    3.1 [Tipo 0](#id31)\n",
    "    \n",
    "    3.2 [Tipo 1](#id32)\n",
    "    \n",
    "    3.3 [Tipo 3](#id33)\n",
    "    \n",
    "    \n",
    "4. [Predicciones contadores tipo 2](#id4)\n",
    "\n",
    "    4.1 [AutoARIMA](#id41)\n",
    "    \n",
    "    4.2 [XGBoost](#id42)\n",
    "    \n",
    "    \n",
    "5. [Postprocesado](#id5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "c9fe4b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "from pmdarima.arima import auto_arima\n",
    "import json\n",
    "import xgboost as xgb\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "65c29c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f50f75",
   "metadata": {},
   "source": [
    "## Carga de datos<a name=\"id1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d714c62b",
   "metadata": {},
   "source": [
    "Cargamos los datos y observamos que tenemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ccadbc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SAMPLETIME</th>\n",
       "      <th>READINGINTEGER</th>\n",
       "      <th>READINGTHOUSANDTH</th>\n",
       "      <th>DELTAINTEGER</th>\n",
       "      <th>DELTATHOUSANDTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-06-13 08:34:09</td>\n",
       "      <td>369320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-06-13 17:34:10</td>\n",
       "      <td>369403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-06-13 18:34:10</td>\n",
       "      <td>369403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-06-13 04:34:10</td>\n",
       "      <td>369284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-06-13 14:34:10</td>\n",
       "      <td>369356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID           SAMPLETIME  READINGINTEGER  READINGTHOUSANDTH  DELTAINTEGER  \\\n",
       "0   0  2019-06-13 08:34:09          369320                0.0            17   \n",
       "1   0  2019-06-13 17:34:10          369403                0.0             2   \n",
       "2   0  2019-06-13 18:34:10          369403                0.0             0   \n",
       "3   0  2019-06-13 04:34:10          369284                0.0             1   \n",
       "4   0  2019-06-13 14:34:10          369356                0.0            28   \n",
       "\n",
       "   DELTATHOUSANDTH  \n",
       "0              0.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              0.0  \n",
       "4              0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/Modelar_UH2022.txt',sep = '|') \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48a5ff0",
   "metadata": {},
   "source": [
    "Vemos el tamaño de los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72fcdea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21404828, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fb9bd2",
   "metadata": {},
   "source": [
    "### Valores nulos en los datos<a name=\"id11\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0406e6a",
   "metadata": {},
   "source": [
    "Vemos si hay valores nulos en los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcca4ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                        0\n",
       "SAMPLETIME                0\n",
       "READINGINTEGER            0\n",
       "READINGTHOUSANDTH    140056\n",
       "DELTAINTEGER              0\n",
       "DELTATHOUSANDTH      140056\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0072f7f0",
   "metadata": {},
   "source": [
    "Como los valores nulos pertenecen a la parte de las milésimas los despreciamos y los imputamos a 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ad8309a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0092e70b",
   "metadata": {},
   "source": [
    "### Las columnas READINGTHOUSANDTH y DELTATHOUSANDTH<a name=\"id12\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df583c1f",
   "metadata": {},
   "source": [
    "Examinemos las columnas *READINGTHOUSANDTH* y *DELTATHOUSANDTH*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "861f3f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number READINGTHOUSANTH != 0: 2428718\n",
      "Number DELTATHOUSANTH != 0: 2428718\n",
      "Minimum READINGTHOUSANTH: 0.0\n",
      "Minimum DELTATHOUSANTH: 0.0\n",
      "Maximum READINGTHOUSANTH: 99.0\n",
      "Maximum DELTATHOUSANTH: 99.0\n"
     ]
    }
   ],
   "source": [
    "print('Number READINGTHOUSANTH != 0:',(df['READINGTHOUSANDTH']!=0).sum())\n",
    "print('Number DELTATHOUSANTH != 0:',(df['READINGTHOUSANDTH']!=0).sum())\n",
    "print('Minimum READINGTHOUSANTH:',df['READINGTHOUSANDTH'].min())\n",
    "print('Minimum DELTATHOUSANTH:',df['DELTATHOUSANDTH'].min())\n",
    "print('Maximum READINGTHOUSANTH:',df['READINGTHOUSANDTH'].max())\n",
    "print('Maximum DELTATHOUSANTH:',df['DELTATHOUSANDTH'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37772282",
   "metadata": {},
   "source": [
    "Aunque el valor máximo para estas columnas es 99, el nombre 'Thousandth' deja claro que estas columnas hacen referencia a las milésimas por lo que dividiremos su valor entre 1000 y se lo agregaremos a la parte de las unidades. No obstante, no creemos que estas dos columnas vayan a tener un gran impacto en las predicciones ya que como máximo estaremos añadiendo 0,099 litros a la medición.\n",
    "\n",
    "Tras agregarlo a las columnas de las unidades nos desharemos tanto de las columnas de las unidades como de las de las milésimas, quedándonos con el agregado de ambas al cual llamaremos *READING* y *DELTA* a partir de ahora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5df7270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SAMPLETIME</th>\n",
       "      <th>DELTA</th>\n",
       "      <th>READING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-06-13 08:34:09</td>\n",
       "      <td>17.0</td>\n",
       "      <td>369320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-06-13 17:34:10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>369403.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-06-13 18:34:10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>369403.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-06-13 04:34:10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>369284.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-06-13 14:34:10</td>\n",
       "      <td>28.0</td>\n",
       "      <td>369356.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID           SAMPLETIME  DELTA   READING\n",
       "0   0  2019-06-13 08:34:09   17.0  369320.0\n",
       "1   0  2019-06-13 17:34:10    2.0  369403.0\n",
       "2   0  2019-06-13 18:34:10    0.0  369403.0\n",
       "3   0  2019-06-13 04:34:10    1.0  369284.0\n",
       "4   0  2019-06-13 14:34:10   28.0  369356.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['DELTA'] = [j+(i/1000) for (j,i) in zip(df['DELTAINTEGER'].values, df['DELTATHOUSANDTH'].values)]\n",
    "df['READING'] = [j+(i/1000) for (j,i) in zip(df['READINGINTEGER'].values, df['READINGTHOUSANDTH'].values)]\n",
    "df.drop(['READINGINTEGER','READINGTHOUSANDTH','DELTAINTEGER','DELTATHOUSANDTH'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5a37eb",
   "metadata": {},
   "source": [
    "### La columna SAMPLETIME<a name=\"id13\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885d76a1",
   "metadata": {},
   "source": [
    "La columna *SAMPLETIME* hace referencia al día y la hora a la que las medidas *READING* y *DELTA* fueron tomadas. Para poder trabajar comodamente con esta columna vamos a convertirla de tipo *string* a tipo *datetime* y a extraer de ella una nueva columna *DATE* en la que solo tendremos la fecha de la medida (sin la hora)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41255471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fecha(date):\n",
    "    return date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "def str2date(string):\n",
    "    return datetime.datetime.strptime(string, '%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a85d84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 21404828/21404828 [10:14<00:00, 34829.19it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 21404828/21404828 [05:06<00:00, 69813.81it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SAMPLETIME</th>\n",
       "      <th>DELTA</th>\n",
       "      <th>READING</th>\n",
       "      <th>DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-06-13 08:34:09</td>\n",
       "      <td>17.0</td>\n",
       "      <td>369320.0</td>\n",
       "      <td>2019-06-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-06-13 17:34:10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>369403.0</td>\n",
       "      <td>2019-06-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-06-13 18:34:10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>369403.0</td>\n",
       "      <td>2019-06-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-06-13 04:34:10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>369284.0</td>\n",
       "      <td>2019-06-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-06-13 14:34:10</td>\n",
       "      <td>28.0</td>\n",
       "      <td>369356.0</td>\n",
       "      <td>2019-06-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID          SAMPLETIME  DELTA   READING        DATE\n",
       "0   0 2019-06-13 08:34:09   17.0  369320.0  2019-06-13\n",
       "1   0 2019-06-13 17:34:10    2.0  369403.0  2019-06-13\n",
       "2   0 2019-06-13 18:34:10    0.0  369403.0  2019-06-13\n",
       "3   0 2019-06-13 04:34:10    1.0  369284.0  2019-06-13\n",
       "4   0 2019-06-13 14:34:10   28.0  369356.0  2019-06-13"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "df['SAMPLETIME'] = df['SAMPLETIME'].progress_apply(str2date)\n",
    "df['DATE'] = df['SAMPLETIME'].progress_apply(get_fecha)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e728ba86",
   "metadata": {},
   "source": [
    "Antes de continuar ordenamos el dataframe por *ID* y *SAMPLETIME* para que sea más interpretable que si está desordenado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a97bad7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(['ID','SAMPLETIME']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374df20b",
   "metadata": {},
   "source": [
    "## Procesado de datos: las columnas DELTA y READING<a name=\"id2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9860c467",
   "metadata": {},
   "source": [
    "Antes de empezar con el tratamiento de las columnas DELTA y READING hay que resaltar que la mayoría de las decisiones que vamos a tomar en este apartado están justificadas por las conclusiones obtenidas en el script de exploración por lo que no nos detendremos a explicar como hemos llegado a ellas (para ello mejor ver el script de exploración)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bb57ff",
   "metadata": {},
   "source": [
    "En primer lugar vamos a definir una función que dadas dos fechas nos devuelva una lista de todas las fechas intermedias. Está función será una utilidad que emplearemos múltiples veces a lo largo de este notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c015e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "given a start date in datetime format \"start_date\" and an \"end_date\" returns a list of strings with the dates from\n",
    "\"start_date\" to \"end_date\".\n",
    "\n",
    "Example:\n",
    "\n",
    "start_date = datetime.date(2019, 9 , 30)\n",
    "end_date = datetime.date(2019, 10, 7)\n",
    "get_date_range(start_date, end_date)\n",
    "'''\n",
    "def get_date_range(start_date, end_date):\n",
    "    number_of_days = (end_date-start_date).days\n",
    "    return [(start_date + datetime.timedelta(days = day)).isoformat() for day in range(number_of_days+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10761248",
   "metadata": {},
   "source": [
    "### Agregar los consumos por fechas<a name=\"id21\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefb319d",
   "metadata": {},
   "source": [
    "En este punto el primer paso claro a dar es agregar por fecha los consumos. No obstante nos encontramos con un serio problema: faltan muchas medidas. Para solventar esto vamos a hacer uso de las dos columnas *DELTA* y *READING*. En un principio si todos los datos están correctos consideramos que *READING* es más fiable. De no ser así, recurrimos a *DELTA* para tratar de completar los datos. Seguiremos el siguiente algoritmo:\n",
    "\n",
    "- IF no hay ninguna medida para un día:\n",
    "    * De momento lo dejamos como **NONE** y lo completaremos más adelante\n",
    "- IF hay 24 medidas, es decir, está completo:\n",
    "    * IF hay 24 medidas para el día anterior:\n",
    "        + Tomamos $max(READING_{actual})-max(READING_{anterior})$ \n",
    "    * IF no hay 24 medidas para el día anterior, es decir, está incompleto:\n",
    "        + Tomamos $sum(DELTA_{actual})$\n",
    "- IF no hay 24 medidas, es decir, está incompleto\n",
    "    * Tomamos $24/N_{medidas}*sum(DELTA_{actual})$, es decir, calculamos el promedio de las medidas que haya y lo múltiplicamos por 24 (como si hubiese 24 medidas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50a69568",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2747/2747 [02:17<00:00, 19.91it/s]\n"
     ]
    }
   ],
   "source": [
    "start_date = datetime.date(2019, 2 , 1)\n",
    "end_date = datetime.date(2020, 1, 31)\n",
    "complete_year = get_date_range(start_date, end_date)\n",
    "\n",
    "delta_df = pd.DataFrame(columns=df['ID'].unique(), index =complete_year)\n",
    "\n",
    "#primero rellenamos la primera columna\n",
    "date = complete_year[0]\n",
    "for i in tqdm(df['ID'].unique()):\n",
    "    one_counter = df[df['ID']==i]\n",
    "    # si no hay ninguna medida\n",
    "    if len(one_counter[one_counter['DATE']==date]) == 0:\n",
    "        delta_df[i][date] = None\n",
    "    # si el contador está completo para ese dia\n",
    "    elif len(one_counter[one_counter['DATE']==date]) >= 24:\n",
    "        delta_df[i][date] = one_counter[one_counter['DATE']==date]['DELTA'].sum()\n",
    "    # si el contador no está completo para ese dia\n",
    "    else:\n",
    "        delta_df[i][date] = (24/len(one_counter[one_counter['DATE']==date])) * \\\n",
    "                         one_counter[one_counter['DATE']==date]['DELTA'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2528e70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2747/2747 [2:07:09<00:00,  2.78s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(df['ID'].unique()):\n",
    "    one_counter = df[df['ID']==i]\n",
    "    for j in range(1, len(complete_year)):\n",
    "        date = complete_year[j]\n",
    "        # si no hay ninguna medida\n",
    "        if len(one_counter[one_counter['DATE']==date]) == 0:\n",
    "            delta_df[i][date] = None\n",
    "        # si el contador está completo para ese dia\n",
    "        elif len(one_counter[one_counter['DATE']==date]) >= 24:\n",
    "            # si el contador está completo para el dia anterior\n",
    "            if len(one_counter[one_counter['DATE']==complete_year[j-1]]) >= 24:\n",
    "                delta_df[i][date] = one_counter[one_counter['DATE']==complete_year[j]]['READING'].max() - \\\n",
    "                                    one_counter[one_counter['DATE']==complete_year[j-1]]['READING'].max()\n",
    "            # si el contador no está completo para el dia anterior\n",
    "            else:\n",
    "                delta_df[i][date] = one_counter[one_counter['DATE']==date]['DELTA'].sum()\n",
    "        # si el contador no está completo para ese dia\n",
    "        else:\n",
    "            delta_df[i][date] = (24/len(one_counter[one_counter['DATE']==date])) * \\\n",
    "                             one_counter[one_counter['DATE']==date]['DELTA'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81008604",
   "metadata": {},
   "source": [
    "Tras aplicar este algoritmo nos quedamos con un dataframe en el que hemos completado todos los días para los que había al menos 1 medida. Sin embargo, los días para los que no había ninguna medida siguen siendo **NONE**. Por lo que necesitaremos otras estrategias para completarlos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b9bd24",
   "metadata": {},
   "source": [
    "### Completar medidas faltantes<a name=\"id22\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb914655",
   "metadata": {},
   "source": [
    "Empezaremos por completar los **NONE** comprendidos entre dos días para los cuales sí se tienen medidas, es decir, que no están ni al principio ni al final de la serie temporal. Para ello tomaremos la última medida *READING* del día en el que empieza la secuencia de **NONE** y la primera medida *READING* del día que termina la secuencia. Si restamos estas dos medidas obtendremos el consumo de agua total durante los días sin medidas, es decir, durante la secuencia de **NONE**. Para interpolar entre estas dos medidas dividiremos este consumo total entre el número de días sin medidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7bfd0d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_huecos(deltas, readings):\n",
    "    consecutive_nones = 0\n",
    "    last_date_not_none = None\n",
    "    none_dates = []\n",
    "    for date in deltas.index:\n",
    "        if deltas[date] == None:\n",
    "            consecutive_nones += 1\n",
    "            none_dates.append(date)\n",
    "        elif deltas[date] != None:\n",
    "            if consecutive_nones > 0:\n",
    "                begin = readings[readings['DATE']==last_date_not_none]['READING'].max()\n",
    "                end = readings[readings['DATE']==date]['READING'].min()\n",
    "                for date_2 in none_dates:\n",
    "                    deltas[date_2] = (end-begin)/consecutive_nones\n",
    "            consecutive_nones = 0\n",
    "            last_date_not_none = date  \n",
    "            none_dates = []\n",
    "    return deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "11d0138d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2747/2747 [17:44<00:00,  2.58it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(df['ID'].unique()): \n",
    "    delta_df[i] = complete_huecos(delta_df[i], df[df['ID']==i][['DATE', 'READING']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80462125",
   "metadata": {},
   "source": [
    "### Tipos de contadores según su serie temporal de consumos<a name=\"id23\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102fec48",
   "metadata": {},
   "source": [
    "Tras este procesado tenemos tres tipos de contadores:\n",
    "- Contadores completos\n",
    "- Contadores a los que les faltan medidas al principio\n",
    "- Contadores a los que les faltan medidas al final\n",
    "- Contadores a los que les faltan medidas al principo y al final\n",
    "\n",
    "Vamos a dividir de manera más formal los contadores en tipos según su serie temporal de consumos:\n",
    "- **Tipo 1:** Contadores cuyas medidas sean todas 0.\n",
    "- **Tipo 2:** Contadores completos al menos en Enero de 2020 no pertenecientes al Tipo 1.\n",
    "- **Tipo 3:** Contadores sin medidas en Noviembre, Diciembre de 2019 y Enero de 2020 pero con medidas en Febrero de 2019 no pertenecientes al Tipo 1.\n",
    "- **Tipo 0:** Contadores no pertencientes a ninguno de los anteriores tipos.\n",
    "\n",
    "Esta división es muy importante ya que dependiendo del tipo del contador se le aplicará una estrategia de predicción u otra. A continuación vamos a fabricar un diccionario en el cual las claves sean los identificadores de los 4 tipos y los valores listas con los IDs pertenecientes a ese tipo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdbfac50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2747/2747 [00:00<00:00, 3102.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tipo_1: 69\n",
      "tipo_2: 2534\n",
      "tipo_3: 44\n",
      "tipo_0: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dicc_tipos = {'tipo_1':[], 'tipo_2':[], 'tipo_3':[], 'tipo_0':[]}\n",
    "\n",
    "for i in tqdm(delta_df.columns):\n",
    "    if delta_df[i].sum()==0:\n",
    "        dicc_tipos['tipo_1'].append(i)\n",
    "    elif delta_df[i][delta_df[i].index >= '2020-01-01'].isna().sum()==0:\n",
    "        dicc_tipos['tipo_2'].append(i)\n",
    "    elif delta_df[i][delta_df[i].index <= '2019-02-14'].isna().sum()==0:\n",
    "        dicc_tipos['tipo_3'].append(i)\n",
    "    else:\n",
    "        dicc_tipos['tipo_0'].append(i)\n",
    "        \n",
    "for t in dicc_tipos:\n",
    "    print(t+':', len(dicc_tipos[t]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d16feec",
   "metadata": {},
   "source": [
    "### Tratar outliers en los consumos y medidas negativas<a name=\"id24\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d41b654",
   "metadata": {},
   "source": [
    "El propósito de esta sección es tratar los outliers en las series temporales de cada contador. Para ello recorrermos todos los contadores en busca de outliers. Consideraremos un outlier cualquier medida *DELTA* tal que\n",
    "\n",
    "$DELTA > Q_3 + IQR \\\\ ó  \\\\ DELTA < Q_1 - IQR$\n",
    "\n",
    "donde $Q_1$ y $Q_3$ son el primer y tercer cuartil respectivamente y $IQR$ es el rango intercuartílico. Transformaremos estos outliers igualándolos a la media de consumos del contador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ee5e2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_df = pd.read_pickle('../data/counters_in_rows_3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65be1aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_df.fillna(value=np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b9d0e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_outliers(delta_serie, IQR, Q1, Q3, avg):\n",
    "    values = delta_serie.values\n",
    "    out = []\n",
    "    for delta in values:\n",
    "        if not np.isnan(delta) and (delta < Q1 - 1.5*IQR or delta > Q3 + 1.5*IQR):\n",
    "            out.append(avg)\n",
    "        else:\n",
    "            out.append(delta)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17fd4679",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2747/2747 [00:04<00:00, 571.64it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(delta_df.columns):\n",
    "    Q1 = np.percentile(delta_df[i][delta_df[i].notna()], 25, method = 'midpoint')\n",
    "    Q3 = np.percentile(delta_df[i][delta_df[i].notna()], 75, method = 'midpoint')\n",
    "    IQR = Q3 - Q1\n",
    "    avg = np.mean(delta_df[i][delta_df[i].notna()])\n",
    "    delta_df[i] = replace_outliers(delta_df[i], IQR, Q1, Q3, avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c10ae99",
   "metadata": {},
   "source": [
    "Por otro lado, no tiene ningún sentido que un dato de consumo sea negativo. Si los datos fuesen perfectos esto no pasaría, pero no es el caso y a pesar de los tratamientos que hemos hecho hasta ahora sigue habiendo algunos consumos negativos. Sencillamente transformaremos estos consumos en ceros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54a4a3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_df[delta_df < 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0945851f",
   "metadata": {},
   "source": [
    "## Predicciones contadores tipos 0, 1 y 3<a name=\"id3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e2c333",
   "metadata": {},
   "source": [
    "El propósito de esta sección es hacer predicciones de consumo para las dos primeras semanas de Febrero de 2020 para cada contador de los tipos 0, 1 y 3. Según el tipo del contador emplearemos estrategias más o menos sofisiticadas. Recordemos cuantos contadores hay de cada tipo:\n",
    "\n",
    "- **Tipo 1:** 68\n",
    "- **Tipo 2:** 2535\n",
    "- **Tipo 3:** 44\n",
    "- **Tipo 0:** 100\n",
    "\n",
    "Nuestros mayores esfuerzos estarán volcados en los contadores de **tipo 2** que tendrán una sección propia, ya que la inmensa mayoría de contadores son de este tipo y además son los más completos. Para ir recopilando las predicciones nos ayudaremos de un DataFrame *results_df* que iremos completando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f74ea869",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.date(2020, 2 , 1)\n",
    "end_date = datetime.date(2020, 2, 14)\n",
    "prediction_dates = get_date_range(start_date, end_date)\n",
    "\n",
    "results_df = pd.DataFrame(columns = delta_df.columns, index = prediction_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f089f82",
   "metadata": {},
   "source": [
    "### Tipo 0<a name=\"id31\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13edba59",
   "metadata": {},
   "source": [
    "Los contadores de **tipo 0** o bien no tienen medidas en Enero de 2020 ni en Febrero de 2019, o bien tienen muy pocas. En cualquier caso son contadores muy difíciles de predecir ya que no tenemos la cantidad apropiada de datos y en el caso de que sí la tengamos son datos poco relevantes (como los consumos de Junio). \n",
    "\n",
    "En este caso hemos considerado que la mejor opción es hacer una estimación grosera. Para el contador $i$ y fecha $j$ se predecirá:\n",
    "\n",
    "$PREDICTION_{i, j}=avg(DELTA_{i})$\n",
    "\n",
    "donde $avg(DELTA_{i})$ es la media de consumos del contador $i$. A pesar de que la media puede no ser precisa ya que está fabricada a partir de pocos datos o datos lejanos a Febrero de 2020, creemos que es la mejor estimación posible en este caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de07bd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1538.64it/s]\n"
     ]
    }
   ],
   "source": [
    "start_date = datetime.date(2019, 2 , 1)\n",
    "end_date = datetime.date(2019, 2, 14)\n",
    "february_2019_two_weeks = get_date_range(start_date, end_date)\n",
    "\n",
    "for i in tqdm(dicc_tipos['tipo_0']):\n",
    "    predictions = []\n",
    "    avg_delta = np.mean(delta_df[i][delta_df[i].notna()])\n",
    "    for j in range(14):\n",
    "        predictions.append(avg_delta)\n",
    "    results_df[i] = predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31684d15",
   "metadata": {},
   "source": [
    "### Tipo 1<a name=\"id32\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116d206c",
   "metadata": {},
   "source": [
    "Los contadores de **tipo 1** son contadores cuyas medidas han sido todas 0 (sean muchas o pocas). Probablemente sean contadores ubicados en viviendas deshabitadas en las que no se consume agua por lo que hemos considerado que la mejor opción es predecir consumo 0 para estos contadores. \n",
    "\n",
    "$PREDICTION_{i, j}=0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adb850a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 2997.98it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(dicc_tipos['tipo_1']):\n",
    "    predictions = []\n",
    "    for j in range(14):\n",
    "        predictions.append(0)\n",
    "    results_df[i] = predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0317de",
   "metadata": {},
   "source": [
    "### Tipo 3<a name=\"id33\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed280f3",
   "metadata": {},
   "source": [
    "Los contadores de **tipo 3** son aquellos sin suficientes medidas en Enero de 2020 (el mes previo a la predicción) pero con medidas en Febrero de 2019 (el mes de la predicción pero un año antes). Para estos contadores consideramos que una mejor estimación que sencillamente la media es la siguiente:\n",
    "\n",
    "$PREDICTION_{i, j}=\\frac{1}{2}\\cdot DELTA_{j, 2019} + \\frac{1}{2}\\cdot avg(\\beta_{i})$\n",
    "\n",
    "donde $DELTA_{j, 2019}$ es el consumo el dia $j$ de 2019 y $\\beta_{i}$ son los consumos durante las dos primeras semanas de Febrero de 2019 del contador $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbc11e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 44/44 [00:00<00:00, 1222.25it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(dicc_tipos['tipo_3']):\n",
    "    predictions = []\n",
    "    avg_beta = delta_df[i][delta_df.index <= '2019-02-14'].mean()\n",
    "    for date in february_2019_two_weeks:\n",
    "        delta_2019 = delta_df[i][date]\n",
    "        predictions.append(0.5*delta_2019 + 0.5*avg_beta)\n",
    "    results_df[i] = predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42db26ca",
   "metadata": {},
   "source": [
    "## Predicciones de contadores tipo 2<a name=\"id4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61eaf503",
   "metadata": {},
   "source": [
    "Hasta ahora hemos hecho predicciones groseras y naïves para apróximadamente un 7% de los contadores cuyos datos no eran buenos por un motivo u otro. Pero realmente el principal esfuerzo de predicción y donde vamos a emplear modelos de machine learning es con los contadores **tipo 2**, que recordemos son contadores que al menos tienen medidas para todo el mes de Enero de 2020.\n",
    "\n",
    "Para estos contadores entrenaremos 2 modelos distintos:\n",
    "- AutoARIMA\n",
    "- XGBoost\n",
    "\n",
    "Una vez tengamos las predicciones de cada uno de los dos modelos para las dos primeras semanas de Febrero, nuestra predicción final será la media de las predicciones de ambos modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669c9db4",
   "metadata": {},
   "source": [
    "### AutoARIMA<a name=\"id41\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515e74ce",
   "metadata": {},
   "source": [
    "El primer modelo que vamos a usar para los contadores de tipo 2 es un AutoARIMA. Este tipo de modelo está enfocado a series temporales de carácter estacional (como el consumo de agua) y se basa en hacer finetuning de los hiperparámetros (p,d,q) que habitualmente tiene un modelo ARIMA. Para la implementación hemos usado la biblioteca pmdarima.\n",
    "\n",
    "https://alkaline-ml.com/pmdarima/modules/generated/pmdarima.arima.auto_arima.html\n",
    "\n",
    "En la documentación arriba referenciada se puede consultar el significado de cada parámetro. Los más importantes que hemos seleccionado nosotros han sido:\n",
    "\n",
    "- **m**: Número de periodos en cada \"estación\" que en este caso por tener daatos diarios y periodicidad semanal es 7 (consultar https://robjhyndman.com/hyndsight/seasonal-periods/).\n",
    "- **stepwise**: Poniendo este parámetro a True el propio modelo se encarga de hacer finetuning sobre sí mismo dando pasos en la dirección de los parámetros que más mejora prometan.\n",
    "\n",
    "En cada iteración del bucle de la siguiente celda tomaremos la serie temporal de un contador de tipo 2, entrenaremos un modelo AutoARIMA y haremos las correspondientes predicciones con el modelo ya entrenado. Guardaremos las predicciones en un dataframe *arima_results*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "be2fcec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                              | 5/2535 [00:38<5:18:37,  7.56s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\auto.py:460: UserWarning: Input time-series is completely constant; returning a (0, 0, 0) ARMA.\n",
      "  warnings.warn('Input time-series is completely constant; '\n",
      "  4%|██▋                                                                           | 89/2535 [08:44<3:42:17,  5.45s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\auto.py:460: UserWarning: Input time-series is completely constant; returning a (0, 0, 0) ARMA.\n",
      "  warnings.warn('Input time-series is completely constant; '\n",
      "  5%|███▌                                                                         | 117/2535 [11:28<4:12:54,  6.28s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\_auto_solvers.py:522: ModelFitWarning: Error fitting  ARIMA(3,1,1)(3,1,1)[7]           (if you do not want to see these warnings, run with error_action=\"ignore\").\n",
      "  warnings.warn(warning_str, ModelFitWarning)\n",
      "  5%|███▌                                                                         | 119/2535 [11:58<7:12:01, 10.73s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\auto.py:460: UserWarning: Input time-series is completely constant; returning a (0, 0, 0) ARMA.\n",
      "  warnings.warn('Input time-series is completely constant; '\n",
      "  5%|████                                                                         | 134/2535 [13:49<4:38:53,  6.97s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\auto.py:460: UserWarning: Input time-series is completely constant; returning a (0, 0, 0) ARMA.\n",
      "  warnings.warn('Input time-series is completely constant; '\n",
      " 11%|████████▏                                                                    | 268/2535 [33:37<3:43:41,  5.92s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\auto.py:460: UserWarning: Input time-series is completely constant; returning a (0, 0, 0) ARMA.\n",
      "  warnings.warn('Input time-series is completely constant; '\n",
      " 11%|████████▎                                                                    | 272/2535 [33:49<2:45:58,  4.40s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\auto.py:460: UserWarning: Input time-series is completely constant; returning a (0, 0, 0) ARMA.\n",
      "  warnings.warn('Input time-series is completely constant; '\n",
      " 13%|█████████▋                                                                   | 318/2535 [39:08<7:06:49, 11.55s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\auto.py:460: UserWarning: Input time-series is completely constant; returning a (0, 0, 0) ARMA.\n",
      "  warnings.warn('Input time-series is completely constant; '\n",
      " 13%|█████████▊                                                                   | 322/2535 [39:15<3:05:29,  5.03s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\_auto_solvers.py:522: ModelFitWarning: Error fitting  ARIMA(1,1,0)(3,1,1)[7]           (if you do not want to see these warnings, run with error_action=\"ignore\").\n",
      "  warnings.warn(warning_str, ModelFitWarning)\n",
      " 14%|██████████▍                                                                  | 344/2535 [41:49<3:49:11,  6.28s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\auto.py:460: UserWarning: Input time-series is completely constant; returning a (0, 0, 0) ARMA.\n",
      "  warnings.warn('Input time-series is completely constant; '\n",
      " 15%|███████████▌                                                                 | 382/2535 [45:32<4:07:01,  6.88s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\auto.py:460: UserWarning: Input time-series is completely constant; returning a (0, 0, 0) ARMA.\n",
      "  warnings.warn('Input time-series is completely constant; '\n",
      " 17%|█████████████▏                                                               | 436/2535 [52:43<3:22:59,  5.80s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\_auto_solvers.py:522: ModelFitWarning: Error fitting  ARIMA(2,1,1)(3,1,2)[7]           (if you do not want to see these warnings, run with error_action=\"ignore\").\n",
      "  warnings.warn(warning_str, ModelFitWarning)\n",
      " 20%|██████████████▉                                                            | 506/2535 [1:00:40<2:58:02,  5.26s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\_auto_solvers.py:522: ModelFitWarning: Error fitting  ARIMA(3,1,0)(3,1,1)[7]           (if you do not want to see these warnings, run with error_action=\"ignore\").\n",
      "  warnings.warn(warning_str, ModelFitWarning)\n",
      " 20%|███████████████                                                            | 510/2535 [1:01:03<2:58:49,  5.30s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\_auto_solvers.py:522: ModelFitWarning: Error fitting  ARIMA(3,1,1)(2,1,0)[7]           (if you do not want to see these warnings, run with error_action=\"ignore\").\n",
      "  warnings.warn(warning_str, ModelFitWarning)\n",
      " 21%|███████████████▌                                                           | 524/2535 [1:02:49<4:00:23,  7.17s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\auto.py:460: UserWarning: Input time-series is completely constant; returning a (0, 0, 0) ARMA.\n",
      "  warnings.warn('Input time-series is completely constant; '\n",
      " 21%|███████████████▉                                                           | 540/2535 [1:04:25<2:20:22,  4.22s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\auto.py:460: UserWarning: Input time-series is completely constant; returning a (0, 0, 0) ARMA.\n",
      "  warnings.warn('Input time-series is completely constant; '\n",
      " 24%|█████████████████▊                                                         | 603/2535 [1:12:08<4:08:31,  7.72s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1899: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  return np.roots(self.polynomial_reduced_ar)**-1\n",
      "C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1906: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  return np.roots(self.polynomial_reduced_ma)**-1\n",
      "C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1906: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  return np.roots(self.polynomial_reduced_ma)**-1\n",
      "C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1906: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  return np.roots(self.polynomial_reduced_ma)**-1\n",
      "C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1899: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  return np.roots(self.polynomial_reduced_ar)**-1\n",
      "C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1906: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  return np.roots(self.polynomial_reduced_ma)**-1\n",
      " 24%|██████████████████▏                                                        | 614/2535 [1:13:30<3:58:45,  7.46s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\auto.py:460: UserWarning: Input time-series is completely constant; returning a (0, 0, 0) ARMA.\n",
      "  warnings.warn('Input time-series is completely constant; '\n",
      " 26%|███████████████████▎                                                       | 653/2535 [1:18:05<2:27:43,  4.71s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\_auto_solvers.py:522: ModelFitWarning: Error fitting  ARIMA(2,1,1)(3,1,2)[7]           (if you do not want to see these warnings, run with error_action=\"ignore\").\n",
      "  warnings.warn(warning_str, ModelFitWarning)\n",
      " 26%|███████████████████▋                                                       | 665/2535 [1:19:35<3:34:57,  6.90s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\_auto_solvers.py:522: ModelFitWarning: Error fitting  ARIMA(1,1,0)(2,1,1)[7]           (if you do not want to see these warnings, run with error_action=\"ignore\").\n",
      "  warnings.warn(warning_str, ModelFitWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|████████████████████▏                                                      | 682/2535 [1:21:29<3:24:03,  6.61s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\auto.py:460: UserWarning: Input time-series is completely constant; returning a (0, 0, 0) ARMA.\n",
      "  warnings.warn('Input time-series is completely constant; '\n",
      " 27%|████████████████████▏                                                      | 684/2535 [1:21:36<2:34:37,  5.01s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\auto.py:460: UserWarning: Input time-series is completely constant; returning a (0, 0, 0) ARMA.\n",
      "  warnings.warn('Input time-series is completely constant; '\n",
      " 28%|████████████████████▊                                                      | 704/2535 [1:23:42<3:58:54,  7.83s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\auto.py:460: UserWarning: Input time-series is completely constant; returning a (0, 0, 0) ARMA.\n",
      "  warnings.warn('Input time-series is completely constant; '\n",
      " 32%|████████████████████████▎                                                  | 822/2535 [1:36:46<3:41:30,  7.76s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\auto.py:460: UserWarning: Input time-series is completely constant; returning a (0, 0, 0) ARMA.\n",
      "  warnings.warn('Input time-series is completely constant; '\n",
      " 33%|█████████████████████████                                                  | 847/2535 [1:39:40<3:16:44,  6.99s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\auto.py:460: UserWarning: Input time-series is completely constant; returning a (0, 0, 0) ARMA.\n",
      "  warnings.warn('Input time-series is completely constant; '\n",
      " 34%|█████████████████████████▏                                                 | 852/2535 [1:40:01<2:24:04,  5.14s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\auto.py:460: UserWarning: Input time-series is completely constant; returning a (0, 0, 0) ARMA.\n",
      "  warnings.warn('Input time-series is completely constant; '\n",
      " 43%|███████████████████████████████▉                                          | 1093/2535 [2:05:39<3:09:11,  7.87s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\auto.py:460: UserWarning: Input time-series is completely constant; returning a (0, 0, 0) ARMA.\n",
      "  warnings.warn('Input time-series is completely constant; '\n",
      " 51%|█████████████████████████████████████▌                                    | 1287/2535 [2:27:06<2:37:56,  7.59s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\auto.py:460: UserWarning: Input time-series is completely constant; returning a (0, 0, 0) ARMA.\n",
      "  warnings.warn('Input time-series is completely constant; '\n",
      " 56%|█████████████████████████████████████████                                 | 1408/2535 [2:40:56<2:23:55,  7.66s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\_auto_solvers.py:522: ModelFitWarning: Error fitting  ARIMA(2,1,1)(1,1,2)[7]           (if you do not want to see these warnings, run with error_action=\"ignore\").\n",
      "  warnings.warn(warning_str, ModelFitWarning)\n",
      " 60%|████████████████████████████████████████████▍                             | 1522/2535 [2:52:57<1:41:22,  6.00s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\_auto_solvers.py:522: ModelFitWarning: Error fitting  ARIMA(3,1,1)(3,1,1)[7]           (if you do not want to see these warnings, run with error_action=\"ignore\").\n",
      "  warnings.warn(warning_str, ModelFitWarning)\n",
      " 60%|████████████████████████████████████████████▍                             | 1523/2535 [2:53:10<2:16:34,  8.10s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\_auto_solvers.py:522: ModelFitWarning: Error fitting  ARIMA(1,1,0)(2,1,2)[7]           (if you do not want to see these warnings, run with error_action=\"ignore\").\n",
      "  warnings.warn(warning_str, ModelFitWarning)\n",
      " 65%|███████████████████████████████████████████████▊                          | 1636/2535 [3:06:11<1:15:07,  5.01s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\auto.py:460: UserWarning: Input time-series is completely constant; returning a (0, 0, 0) ARMA.\n",
      "  warnings.warn('Input time-series is completely constant; '\n",
      " 66%|█████████████████████████████████████████████████▉                          | 1666/2535 [3:08:38<44:29,  3.07s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\auto.py:460: UserWarning: Input time-series is completely constant; returning a (0, 0, 0) ARMA.\n",
      "  warnings.warn('Input time-series is completely constant; '\n",
      " 67%|█████████████████████████████████████████████████▍                        | 1695/2535 [3:11:49<1:12:47,  5.20s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\auto.py:460: UserWarning: Input time-series is completely constant; returning a (0, 0, 0) ARMA.\n",
      "  warnings.warn('Input time-series is completely constant; '\n",
      "C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\auto.py:460: UserWarning: Input time-series is completely constant; returning a (0, 0, 0) ARMA.\n",
      "  warnings.warn('Input time-series is completely constant; '\n",
      " 68%|██████████████████████████████████████████████████▍                       | 1726/2535 [3:14:53<1:33:54,  6.96s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\_auto_solvers.py:522: ModelFitWarning: Error fitting  ARIMA(2,1,0)(2,1,1)[7]           (if you do not want to see these warnings, run with error_action=\"ignore\").\n",
      "  warnings.warn(warning_str, ModelFitWarning)\n",
      " 71%|████████████████████████████████████████████████████▌                     | 1801/2535 [3:23:57<1:35:56,  7.84s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\_auto_solvers.py:522: ModelFitWarning: Error fitting  ARIMA(3,1,0)(1,1,1)[7]           (if you do not want to see these warnings, run with error_action=\"ignore\").\n",
      "  warnings.warn(warning_str, ModelFitWarning)\n",
      " 73%|█████████████████████████████████████████████████████▉                    | 1846/2535 [3:30:27<2:09:07, 11.24s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\auto.py:460: UserWarning: Input time-series is completely constant; returning a (0, 0, 0) ARMA.\n",
      "  warnings.warn('Input time-series is completely constant; '\n",
      " 73%|██████████████████████████████████████████████████████                    | 1850/2535 [3:30:46<1:13:01,  6.40s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\_auto_solvers.py:522: ModelFitWarning: Error fitting  ARIMA(1,1,0)(2,1,2)[7]           (if you do not want to see these warnings, run with error_action=\"ignore\").\n",
      "  warnings.warn(warning_str, ModelFitWarning)\n",
      " 74%|████████████████████████████████████████████████████████▏                   | 1875/2535 [3:33:35<59:15,  5.39s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\auto.py:460: UserWarning: Input time-series is completely constant; returning a (0, 0, 0) ARMA.\n",
      "  warnings.warn('Input time-series is completely constant; '\n",
      " 77%|█████████████████████████████████████████████████████████▏                | 1958/2535 [3:43:16<1:06:28,  6.91s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\auto.py:460: UserWarning: Input time-series is completely constant; returning a (0, 0, 0) ARMA.\n",
      "  warnings.warn('Input time-series is completely constant; '\n",
      " 80%|███████████████████████████████████████████████████████████▌              | 2039/2535 [3:53:40<1:09:12,  8.37s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\auto.py:460: UserWarning: Input time-series is completely constant; returning a (0, 0, 0) ARMA.\n",
      "  warnings.warn('Input time-series is completely constant; '\n",
      " 81%|█████████████████████████████████████████████████████████████▋              | 2057/2535 [3:55:37<41:29,  5.21s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1899: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  return np.roots(self.polynomial_reduced_ar)**-1\n",
      "C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1906: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  return np.roots(self.polynomial_reduced_ma)**-1\n",
      "C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1906: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  return np.roots(self.polynomial_reduced_ma)**-1\n",
      "C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1906: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  return np.roots(self.polynomial_reduced_ma)**-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1899: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  return np.roots(self.polynomial_reduced_ar)**-1\n",
      "C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1906: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  return np.roots(self.polynomial_reduced_ma)**-1\n",
      " 81%|█████████████████████████████████████████████████████████████▋              | 2059/2535 [3:55:41<26:48,  3.38s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\auto.py:460: UserWarning: Input time-series is completely constant; returning a (0, 0, 0) ARMA.\n",
      "  warnings.warn('Input time-series is completely constant; '\n",
      " 85%|████████████████████████████████████████████████████████████████▌           | 2155/2535 [4:06:26<36:46,  5.81s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\_auto_solvers.py:522: ModelFitWarning: Error fitting  ARIMA(2,1,0)(2,1,2)[7]           (if you do not want to see these warnings, run with error_action=\"ignore\").\n",
      "  warnings.warn(warning_str, ModelFitWarning)\n",
      "C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\_auto_solvers.py:522: ModelFitWarning: Error fitting  ARIMA(3,1,0)(2,1,2)[7]           (if you do not want to see these warnings, run with error_action=\"ignore\").\n",
      "  warnings.warn(warning_str, ModelFitWarning)\n",
      " 85%|████████████████████████████████████████████████████████████████▊           | 2162/2535 [4:07:10<40:28,  6.51s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\auto.py:460: UserWarning: Input time-series is completely constant; returning a (0, 0, 0) ARMA.\n",
      "  warnings.warn('Input time-series is completely constant; '\n",
      " 87%|██████████████████████████████████████████████████████████████████▏         | 2208/2535 [4:11:37<31:09,  5.72s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\_auto_solvers.py:522: ModelFitWarning: Error fitting  ARIMA(1,1,0)(3,1,1)[7]           (if you do not want to see these warnings, run with error_action=\"ignore\").\n",
      "  warnings.warn(warning_str, ModelFitWarning)\n",
      " 90%|████████████████████████████████████████████████████████████████████▋       | 2291/2535 [4:20:24<28:00,  6.89s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1899: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  return np.roots(self.polynomial_reduced_ar)**-1\n",
      "C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1899: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  return np.roots(self.polynomial_reduced_ar)**-1\n",
      "C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1899: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  return np.roots(self.polynomial_reduced_ar)**-1\n",
      "C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1906: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  return np.roots(self.polynomial_reduced_ma)**-1\n",
      "C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1899: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  return np.roots(self.polynomial_reduced_ar)**-1\n",
      "C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1906: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  return np.roots(self.polynomial_reduced_ma)**-1\n",
      "C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1899: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  return np.roots(self.polynomial_reduced_ar)**-1\n",
      "C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:1906: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  return np.roots(self.polynomial_reduced_ma)**-1\n",
      " 94%|███████████████████████████████████████████████████████████████████████▊    | 2394/2535 [4:31:45<19:04,  8.12s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\auto.py:460: UserWarning: Input time-series is completely constant; returning a (0, 0, 0) ARMA.\n",
      "  warnings.warn('Input time-series is completely constant; '\n",
      "100%|███████████████████████████████████████████████████████████████████████████▊| 2528/2535 [4:44:05<00:37,  5.43s/it]C:\\Users\\sergi\\Anaconda3\\envs\\cajamar\\lib\\site-packages\\pmdarima\\arima\\_auto_solvers.py:522: ModelFitWarning: Error fitting  ARIMA(0,1,1)(3,1,2)[7]           (if you do not want to see these warnings, run with error_action=\"ignore\").\n",
      "  warnings.warn(warning_str, ModelFitWarning)\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2535/2535 [4:45:09<00:00,  6.75s/it]\n"
     ]
    }
   ],
   "source": [
    "arima_results = pd.DataFrame(columns = dicc_tipos['tipo_2'], index = prediction_dates)\n",
    "\n",
    "for i in tqdm(dicc_tipos['tipo_2']):\n",
    "    one_counter = delta_df[i][delta_df.index >= '2019-11-02'].dropna()\n",
    "    \n",
    "    arima_model = auto_arima(one_counter, \n",
    "                    start_p=0, \n",
    "                    d=1, \n",
    "                    start_q=0, \n",
    "                    max_p=3, \n",
    "                    max_d=3, \n",
    "                    max_q=3, \n",
    "                    start_P=0, \n",
    "                    D=1, \n",
    "                    start_Q=0, \n",
    "                    max_P=3, \n",
    "                    max_D=3, \n",
    "                    max_Q=3, \n",
    "                    m=7, \n",
    "                    seasonal=True, \n",
    "                    error_action='warn', \n",
    "                    trace=False, \n",
    "                    supress_warnings=True, \n",
    "                    stepwise=True, \n",
    "                    random_state=2517, \n",
    "                    #n_jobs=4,\n",
    "                    n_fits=10)   \n",
    "    arima_results[i] = arima_model.predict(n_periods = 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493ab130",
   "metadata": {},
   "source": [
    "### XGBoost<a name=\"id42\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c68c18",
   "metadata": {},
   "source": [
    "Como adelantábamos, el segundo modelo será XGBoost Regressor. Para enriquecer el modelo generaremos nuevas variables a partir de la variable fecha. Generaremos dos tipos de variables:\n",
    "1. Temporales\n",
    "2. Climáticas\n",
    "\n",
    "Las **variables temporales** que generaremos serán las siguientes:\n",
    "- Transformaciones seno y coseno del día de la semana. Es decir, a partir de la fecha obtenemos el día de la semana y a continuación hacemos las siguientes dos transformaciones para codificarlo como variables continuas ($W$ es el número del día de la semana siendo 1 Lunes, 2 Martes, etc.):\n",
    "\n",
    "$sin_{W}=sin(\\frac{2\\cdot \\pi \\cdot W}{7}) \\\\\n",
    "cos_{W}=cos(\\frac{2\\cdot \\pi \\cdot W}{7})$\n",
    "\n",
    "- Transformaciones seno y coseno del día del año. De la misma manera que el día de la semana si $Y$ es el número del día del año (1 para el 1 de Enero, 2 para el 2 de Enero, etc.) hacemos las siguientes transormaciones:\n",
    "\n",
    "$sin_{Y}=sin(\\frac{2\\cdot \\pi \\cdot Y}{365}) \\\\\n",
    "cos_{Y}=cos(\\frac{2\\cdot \\pi \\cdot Y}{365})$\n",
    "\n",
    "- Finalmente generamos una última variables *IS_WEEKEND* que tomará valor 1 si la fecha corresponde con un Sábado o un Domingo y 0 en caso contrario.\n",
    "\n",
    "Por otra parte generamos las siguientes **variables climáticas** tomando los datos meteorológicos de una de las estaciones de AEMET en Valencia (https://opendata.aemet.es/centrodedescargas/inicio):\n",
    "- Temperatura media\n",
    "- Sol\n",
    "- Precipitaciones\n",
    "\n",
    "Una vez generadas todas estas variables (tanto para el conjunto de train como para las fechas de Febrero en las que tenemos que hacer la predicción) procedemos a iterar sobre cada contador del tipo 2 al igual que hicimos con los modelos AutoARIMA. Para cada contador $i$ entrenamos un XGBoost donde *X_train* está compuesto por las variables temporales y climáticas generadas en las fechas para las que $i$ tenga datos e *y_train* por los consumos del contador $i$. Una vez entrenado empleamos este modelo para predecir los consumos del contador $i$ de las dos primeras semanas de febrero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "64cbe3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>WEEKDAY</th>\n",
       "      <th>YEAR_DAY</th>\n",
       "      <th>IS_WEEKEND</th>\n",
       "      <th>sin_WEEKDAY</th>\n",
       "      <th>cos_WEEKDAY</th>\n",
       "      <th>sin_year_day</th>\n",
       "      <th>cos_year_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-11-02</th>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>5</td>\n",
       "      <td>306</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>-0.849817</td>\n",
       "      <td>0.527078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-03</th>\n",
       "      <td>2019-11-03</td>\n",
       "      <td>6</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>-0.840618</td>\n",
       "      <td>0.541628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-04</th>\n",
       "      <td>2019-11-04</td>\n",
       "      <td>0</td>\n",
       "      <td>308</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.831171</td>\n",
       "      <td>0.556017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-05</th>\n",
       "      <td>2019-11-05</td>\n",
       "      <td>1</td>\n",
       "      <td>309</td>\n",
       "      <td>0</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>-0.821477</td>\n",
       "      <td>0.570242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-06</th>\n",
       "      <td>2019-11-06</td>\n",
       "      <td>2</td>\n",
       "      <td>310</td>\n",
       "      <td>0</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>-0.811539</td>\n",
       "      <td>0.584298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 DATE  WEEKDAY  YEAR_DAY  IS_WEEKEND  sin_WEEKDAY  \\\n",
       "2019-11-02 2019-11-02        5       306           1    -0.974928   \n",
       "2019-11-03 2019-11-03        6       307           1    -0.781831   \n",
       "2019-11-04 2019-11-04        0       308           0     0.000000   \n",
       "2019-11-05 2019-11-05        1       309           0     0.781831   \n",
       "2019-11-06 2019-11-06        2       310           0     0.974928   \n",
       "\n",
       "            cos_WEEKDAY  sin_year_day  cos_year_day  \n",
       "2019-11-02    -0.222521     -0.849817      0.527078  \n",
       "2019-11-03     0.623490     -0.840618      0.541628  \n",
       "2019-11-04     1.000000     -0.831171      0.556017  \n",
       "2019-11-05     0.623490     -0.821477      0.570242  \n",
       "2019-11-06    -0.222521     -0.811539      0.584298  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_weekend(weekday):\n",
    "    if weekday==5 or weekday==6:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "start_date = datetime.date(2019, 11, 2)\n",
    "end_date = datetime.date(2020, 2, 14)\n",
    "all_dates = get_date_range(start_date, end_date)\n",
    "\n",
    "time_variables = pd.DataFrame(index = all_dates)\n",
    "\n",
    "# variables temporales\n",
    "time_variables['DATE'] = all_dates\n",
    "time_variables['DATE'] = time_variables['DATE'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d\"))\n",
    "time_variables['WEEKDAY'] = time_variables['DATE'].apply(lambda x: x.weekday())\n",
    "time_variables['YEAR_DAY'] = time_variables['DATE'].apply(lambda x: x.timetuple().tm_yday)\n",
    "time_variables['IS_WEEKEND'] = time_variables['WEEKDAY'].apply(is_weekend)\n",
    "days_in_a_week = 7\n",
    "time_variables['sin_WEEKDAY'] = np.sin(2*np.pi*time_variables['WEEKDAY']/days_in_a_week)\n",
    "time_variables['cos_WEEKDAY'] = np.cos(2*np.pi*time_variables['WEEKDAY']/days_in_a_week)\n",
    "days_in_a_year = 365\n",
    "time_variables['sin_year_day'] = np.sin(2*np.pi*time_variables['YEAR_DAY']/days_in_a_year)\n",
    "time_variables['cos_year_day'] = np.cos(2*np.pi*time_variables['YEAR_DAY']/days_in_a_year)\n",
    "\n",
    "time_variables.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1f4da187",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatura_valencia = pd.read_json('../data/Temperatura_Valencia.txt')\n",
    "temperatura_valencia = temperatura_valencia[['fecha', 'tmed', 'tmin', 'tmax', 'sol', 'prec']]\n",
    "temperatura_valencia['prec'] = temperatura_valencia['prec'].replace('Ip', None)\n",
    "temperatura_valencia = temperatura_valencia.fillna(method='ffill')\n",
    "\n",
    "temperatura_valencia['tmed'] = temperatura_valencia['tmed'].apply(lambda x: float(x.replace(',','.')))\n",
    "temperatura_valencia['tmin'] = temperatura_valencia['tmin'].apply(lambda x: float(x.replace(',','.')))\n",
    "temperatura_valencia['tmax'] = temperatura_valencia['tmax'].apply(lambda x: float(x.replace(',','.')))\n",
    "temperatura_valencia['sol'] = temperatura_valencia['sol'].apply(lambda x: float(x.replace(',','.')))\n",
    "temperatura_valencia['prec'] = temperatura_valencia['prec'].apply(lambda x: float(x.replace(',','.')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b9938feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmed</th>\n",
       "      <th>tmin</th>\n",
       "      <th>tmax</th>\n",
       "      <th>sol</th>\n",
       "      <th>prec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tmed</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.965356</td>\n",
       "      <td>0.959125</td>\n",
       "      <td>0.348302</td>\n",
       "      <td>-0.137641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmin</th>\n",
       "      <td>0.965356</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.852129</td>\n",
       "      <td>0.211119</td>\n",
       "      <td>-0.041143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmax</th>\n",
       "      <td>0.959125</td>\n",
       "      <td>0.852129</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.470573</td>\n",
       "      <td>-0.231800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sol</th>\n",
       "      <td>0.348302</td>\n",
       "      <td>0.211119</td>\n",
       "      <td>0.470573</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.405306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prec</th>\n",
       "      <td>-0.137641</td>\n",
       "      <td>-0.041143</td>\n",
       "      <td>-0.231800</td>\n",
       "      <td>-0.405306</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tmed      tmin      tmax       sol      prec\n",
       "tmed  1.000000  0.965356  0.959125  0.348302 -0.137641\n",
       "tmin  0.965356  1.000000  0.852129  0.211119 -0.041143\n",
       "tmax  0.959125  0.852129  1.000000  0.470573 -0.231800\n",
       "sol   0.348302  0.211119  0.470573  1.000000 -0.405306\n",
       "prec -0.137641 -0.041143 -0.231800 -0.405306  1.000000"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperatura_valencia[['tmed', 'tmin', 'tmax', 'sol', 'prec']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665eaa54",
   "metadata": {},
   "source": [
    "Como se podía esperar temperatura media, mínima y máxima están muy correladas por lo que nos quedamos solo con la media."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "82d0017f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha</th>\n",
       "      <th>tmed</th>\n",
       "      <th>sol</th>\n",
       "      <th>prec</th>\n",
       "      <th>DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>11.9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>10.5</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>10.2</td>\n",
       "      <td>8.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-05</td>\n",
       "      <td>12.4</td>\n",
       "      <td>8.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-01-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fecha  tmed  sol  prec       DATE\n",
       "0  2019-01-01  11.9  6.0   0.0 2019-01-01\n",
       "1  2019-01-02  12.0  8.7   0.0 2019-01-02\n",
       "2  2019-01-03  10.5  7.7   0.0 2019-01-03\n",
       "3  2019-01-04  10.2  8.4   0.0 2019-01-04\n",
       "4  2019-01-05  12.4  8.7   0.0 2019-01-05"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperatura_valencia = temperatura_valencia[['fecha', 'tmed', 'sol', 'prec']]\n",
    "temperatura_valencia['DATE'] = temperatura_valencia['fecha'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d\"))\n",
    "temperatura_valencia.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "71edf791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>IS_WEEKEND</th>\n",
       "      <th>sin_WEEKDAY</th>\n",
       "      <th>cos_WEEKDAY</th>\n",
       "      <th>sin_year_day</th>\n",
       "      <th>cos_year_day</th>\n",
       "      <th>fecha</th>\n",
       "      <th>tmed</th>\n",
       "      <th>sol</th>\n",
       "      <th>prec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>-0.849817</td>\n",
       "      <td>0.527078</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>24.8</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-03</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>-0.840618</td>\n",
       "      <td>0.541628</td>\n",
       "      <td>2019-11-03</td>\n",
       "      <td>22.8</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-11-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.831171</td>\n",
       "      <td>0.556017</td>\n",
       "      <td>2019-11-04</td>\n",
       "      <td>21.4</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.623490</td>\n",
       "      <td>-0.821477</td>\n",
       "      <td>0.570242</td>\n",
       "      <td>2019-11-05</td>\n",
       "      <td>18.2</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-11-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>-0.222521</td>\n",
       "      <td>-0.811539</td>\n",
       "      <td>0.584298</td>\n",
       "      <td>2019-11-06</td>\n",
       "      <td>17.6</td>\n",
       "      <td>9.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DATE  IS_WEEKEND  sin_WEEKDAY  cos_WEEKDAY  sin_year_day  \\\n",
       "0 2019-11-02           1    -0.974928    -0.222521     -0.849817   \n",
       "1 2019-11-03           1    -0.781831     0.623490     -0.840618   \n",
       "2 2019-11-04           0     0.000000     1.000000     -0.831171   \n",
       "3 2019-11-05           0     0.781831     0.623490     -0.821477   \n",
       "4 2019-11-06           0     0.974928    -0.222521     -0.811539   \n",
       "\n",
       "   cos_year_day       fecha  tmed  sol  prec  \n",
       "0      0.527078  2019-11-02  24.8  5.7   0.0  \n",
       "1      0.541628  2019-11-03  22.8  7.6   0.0  \n",
       "2      0.556017  2019-11-04  21.4  6.9   0.0  \n",
       "3      0.570242  2019-11-05  18.2  9.2   0.0  \n",
       "4      0.584298  2019-11-06  17.6  9.1   0.0  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_variables = pd.merge(time_variables, temperatura_valencia, on='DATE')\n",
    "all_variables.drop(['WEEKDAY', 'YEAR_DAY'], axis=1, inplace=True)\n",
    "all_variables.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "43ac1bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2534/2534 [19:45<00:00,  2.14it/s]\n"
     ]
    }
   ],
   "source": [
    "xgboost_results = pd.DataFrame(columns = dicc_tipos['tipo_2'], index = prediction_dates)\n",
    "\n",
    "for i in tqdm(dicc_tipos['tipo_2']):\n",
    "    one_counter = delta_df[i][delta_df.index >= '2019-11-02'].dropna()\n",
    "    one_counter_all_variables = pd.merge(one_counter, all_variables, left_on=one_counter.index, right_on='fecha', how='left')\n",
    "    one_counter_all_variables['DELTA'] = one_counter_all_variables[i]\n",
    "    one_counter_all_variables.drop(['DATE','fecha', i], axis=1, inplace=True)\n",
    "\n",
    "    X_train = one_counter_all_variables.drop('DELTA', axis=1)\n",
    "    y_train = one_counter_all_variables['DELTA']\n",
    "\n",
    "    X_test = all_variables.drop(['DATE','fecha'], axis=1)[-14:]\n",
    "\n",
    "    model = xgb.XGBRegressor(\n",
    "        n_estimators=1000,\n",
    "        reg_lambda=1,\n",
    "        gamma=0,\n",
    "        max_depth=5\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    xgboost_results[i] =  model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "de53bbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_results.to_pickle('../data/xgboost_results_1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8b20cc",
   "metadata": {},
   "source": [
    "La predicción final que añadimos al dataframe *results_df* es la media entre la predicción del modelo AutoARIMA y la predicción del modelo XGBoost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "4ddf9218",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2534/2534 [00:01<00:00, 1774.51it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(dicc_tipos['tipo_2']):\n",
    "    results_df[i] = (arima_results[i] + xgboost_results[i])/2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac40bbe4",
   "metadata": {},
   "source": [
    "## Postprocesado<a name=\"id5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29adc49c",
   "metadata": {},
   "source": [
    "En este apartado detallamos los pequeños pasos de postprocesado antes de guardar la predicción final."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1201c2b",
   "metadata": {},
   "source": [
    "En primer lugar, dado que no tiene sentido predecir un consumo negativo, aquellos consumos predichos que sean negativos los ponemos a 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d058f778",
   "metadata": {},
   "source": [
    "Finalmente pasamos nuestros resultados al formato requerido por el enunciado del concurso y guardamos el archivo. En este punto cabe resaltar que una de las pruebas que llevamos a cabo fue si era mejor emplear un modelo separado para calcular los consumos totales semanales. El resultado fue que era mejor predecir los consumos diarios y luego agregarlos por semanas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "20c4b63c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[results_df < 0] = 0\n",
    "(results_df < 0).sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "e7cd8115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>2020-02-01</th>\n",
       "      <th>2020-02-02</th>\n",
       "      <th>2020-02-03</th>\n",
       "      <th>2020-02-04</th>\n",
       "      <th>2020-02-05</th>\n",
       "      <th>2020-02-06</th>\n",
       "      <th>2020-02-07</th>\n",
       "      <th>Semana_1</th>\n",
       "      <th>Semana_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>328.9435</td>\n",
       "      <td>311.2076</td>\n",
       "      <td>283.8836</td>\n",
       "      <td>293.8022</td>\n",
       "      <td>326.4230</td>\n",
       "      <td>296.3539</td>\n",
       "      <td>373.6840</td>\n",
       "      <td>2214.2978</td>\n",
       "      <td>2218.1058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.1147</td>\n",
       "      <td>5.0981</td>\n",
       "      <td>10.4217</td>\n",
       "      <td>8.5452</td>\n",
       "      <td>5.5314</td>\n",
       "      <td>6.2061</td>\n",
       "      <td>5.1523</td>\n",
       "      <td>45.0694</td>\n",
       "      <td>40.6259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>37.2041</td>\n",
       "      <td>39.9459</td>\n",
       "      <td>45.8988</td>\n",
       "      <td>46.3428</td>\n",
       "      <td>34.4310</td>\n",
       "      <td>30.7549</td>\n",
       "      <td>38.9017</td>\n",
       "      <td>273.4792</td>\n",
       "      <td>270.2077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>463.4875</td>\n",
       "      <td>348.9227</td>\n",
       "      <td>294.2648</td>\n",
       "      <td>347.3875</td>\n",
       "      <td>380.6865</td>\n",
       "      <td>337.7756</td>\n",
       "      <td>429.2843</td>\n",
       "      <td>2601.8089</td>\n",
       "      <td>2639.6726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>350.2188</td>\n",
       "      <td>335.4870</td>\n",
       "      <td>316.2345</td>\n",
       "      <td>309.3496</td>\n",
       "      <td>338.8879</td>\n",
       "      <td>336.3996</td>\n",
       "      <td>308.6230</td>\n",
       "      <td>2295.2004</td>\n",
       "      <td>2457.0977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2746</th>\n",
       "      <td>2746</td>\n",
       "      <td>649.0352</td>\n",
       "      <td>649.0352</td>\n",
       "      <td>649.0352</td>\n",
       "      <td>649.0352</td>\n",
       "      <td>649.0352</td>\n",
       "      <td>649.0352</td>\n",
       "      <td>649.0352</td>\n",
       "      <td>4543.2461</td>\n",
       "      <td>4543.2461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2747</th>\n",
       "      <td>2747</td>\n",
       "      <td>36.0000</td>\n",
       "      <td>36.0000</td>\n",
       "      <td>36.0000</td>\n",
       "      <td>36.0000</td>\n",
       "      <td>36.0000</td>\n",
       "      <td>36.0000</td>\n",
       "      <td>36.0000</td>\n",
       "      <td>252.0000</td>\n",
       "      <td>252.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2748</th>\n",
       "      <td>2748</td>\n",
       "      <td>442.5870</td>\n",
       "      <td>442.5870</td>\n",
       "      <td>442.5870</td>\n",
       "      <td>442.5870</td>\n",
       "      <td>442.5870</td>\n",
       "      <td>442.5870</td>\n",
       "      <td>442.5870</td>\n",
       "      <td>3098.1087</td>\n",
       "      <td>3098.1087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2749</th>\n",
       "      <td>2749</td>\n",
       "      <td>118.4536</td>\n",
       "      <td>118.4536</td>\n",
       "      <td>118.4536</td>\n",
       "      <td>118.4536</td>\n",
       "      <td>118.4536</td>\n",
       "      <td>118.4536</td>\n",
       "      <td>118.4536</td>\n",
       "      <td>829.1749</td>\n",
       "      <td>829.1749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756</th>\n",
       "      <td>2756</td>\n",
       "      <td>72.0000</td>\n",
       "      <td>72.0000</td>\n",
       "      <td>72.0000</td>\n",
       "      <td>72.0000</td>\n",
       "      <td>72.0000</td>\n",
       "      <td>72.0000</td>\n",
       "      <td>72.0000</td>\n",
       "      <td>504.0000</td>\n",
       "      <td>504.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2747 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  2020-02-01  2020-02-02  2020-02-03  2020-02-04  2020-02-05  \\\n",
       "0        0    328.9435    311.2076    283.8836    293.8022    326.4230   \n",
       "1        1      4.1147      5.0981     10.4217      8.5452      5.5314   \n",
       "2        2     37.2041     39.9459     45.8988     46.3428     34.4310   \n",
       "3        3    463.4875    348.9227    294.2648    347.3875    380.6865   \n",
       "4        4    350.2188    335.4870    316.2345    309.3496    338.8879   \n",
       "...    ...         ...         ...         ...         ...         ...   \n",
       "2746  2746    649.0352    649.0352    649.0352    649.0352    649.0352   \n",
       "2747  2747     36.0000     36.0000     36.0000     36.0000     36.0000   \n",
       "2748  2748    442.5870    442.5870    442.5870    442.5870    442.5870   \n",
       "2749  2749    118.4536    118.4536    118.4536    118.4536    118.4536   \n",
       "2756  2756     72.0000     72.0000     72.0000     72.0000     72.0000   \n",
       "\n",
       "      2020-02-06  2020-02-07   Semana_1   Semana_2  \n",
       "0       296.3539    373.6840  2214.2978  2218.1058  \n",
       "1         6.2061      5.1523    45.0694    40.6259  \n",
       "2        30.7549     38.9017   273.4792   270.2077  \n",
       "3       337.7756    429.2843  2601.8089  2639.6726  \n",
       "4       336.3996    308.6230  2295.2004  2457.0977  \n",
       "...          ...         ...        ...        ...  \n",
       "2746    649.0352    649.0352  4543.2461  4543.2461  \n",
       "2747     36.0000     36.0000   252.0000   252.0000  \n",
       "2748    442.5870    442.5870  3098.1087  3098.1087  \n",
       "2749    118.4536    118.4536   829.1749   829.1749  \n",
       "2756     72.0000     72.0000   504.0000   504.0000  \n",
       "\n",
       "[2747 rows x 10 columns]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results = results_df.T\n",
    "final_results['Semana_1'] = final_results[['2020-02-01','2020-02-02','2020-02-03','2020-02-04','2020-02-05','2020-02-06','2020-02-07']].sum(axis=1)\n",
    "final_results['Semana_2'] = final_results[['2020-02-08','2020-02-09','2020-02-10','2020-02-11','2020-02-12','2020-02-13','2020-02-14']].sum(axis=1)\n",
    "final_results.drop(['2020-02-08','2020-02-09','2020-02-10','2020-02-11','2020-02-12','2020-02-13','2020-02-14'], axis=1, inplace=True)\n",
    "final_results['ID'] = final_results.index\n",
    "final_results = final_results[['ID','2020-02-01','2020-02-02','2020-02-03','2020-02-04','2020-02-05','2020-02-06','2020-02-07','Semana_1','Semana_2']]\n",
    "final_results = round(final_results, 4)\n",
    "final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "c637e24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/La Manzana de Newton.txt'\n",
    "final_results.to_csv(path, sep = '|', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d74e87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
